{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.vgg import VGG\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import scipy.misc\n",
    "import random\n",
    "import sys\n",
    "\n",
    "if '/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define FCN16s model for deconvolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN16s(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_net, n_class):\n",
    "        super(FCN16s, self).__init__()\n",
    "        self.n_class = n_class\n",
    "        self.pretrained_net = pretrained_net\n",
    "        self.relu    = nn.ReLU(inplace = True)\n",
    "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn1     = nn.BatchNorm2d(512)\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn2     = nn.BatchNorm2d(256)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn3     = nn.BatchNorm2d(128)\n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn4     = nn.BatchNorm2d(64)\n",
    "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn5     = nn.BatchNorm2d(32)\n",
    "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pretrained_net(x)\n",
    "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
    "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
    "\n",
    "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
    "        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)\n",
    "        score = self.bn2(self.relu(self.deconv2(score)))  # size=(N, 256, x.H/8, x.W/8)\n",
    "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
    "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
    "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
    "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VGG16 for convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet(VGG):\n",
    "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
    "        super(VGGNet, self).__init__(make_layers(cfg[model]))\n",
    "        self.ranges = ranges[model]\n",
    "\n",
    "        if pretrained:\n",
    "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in super().parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
    "            del self.classifier\n",
    "\n",
    "        if show_params:\n",
    "            for name, param in self.named_parameters():\n",
    "                print(name, param.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = {}\n",
    "\n",
    "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
    "        for idx in range(len(self.ranges)):\n",
    "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):      \n",
    "                x = self.features[layer](x)\n",
    "            output[\"x%d\"%(idx+1)] = x\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = {\n",
    "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
    "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
    "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
    "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
    "}\n",
    "\n",
    "# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
    "cfg = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs     = 10  #500\n",
    "lr         = 1e-4\n",
    "momentum   = 0\n",
    "w_decay    = 1e-5\n",
    "step_size  = 50\n",
    "gamma      = 0.5\n",
    "model_use  = \"ds\" #\"domain_randomization\"#\"ds_final\"#\"style_transfer\"#\"virtual\" # \"products_20\n",
    "n_class = 21\n",
    "class_list = [\"3m\", \"andes\", \"cocacola\", \"crayola\", \"folgers\", \"kellogg\", \"hunts\", \"heineken\", \"kleenex\", \"libava\", \"macadamia\", \"milo\", \"mm\", \"pocky\", \"stax\", \"swissmiss\", \"vanish\", \"viva\", \"raisins\", \"kotex\"]\n",
    "# class_list = [\"3m\", \"andes\", \"cocacola\", \"crayola\", \"folgers\", \"kellogg\", \"milo\", \"stax\", \"swissmiss\", \"viva\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define path, directory trainning environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish cuda loading, time elapsed 3.31510615349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "data_dir  = os.path.join(\"data\", model_use)\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"Data not found!\")\n",
    "# create dir for model\n",
    "model_dir = os.path.join(\"models\", model_use)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "# create dir for score\n",
    "score_dir = os.path.join(\"scores\", model_use)\n",
    "if not os.path.exists(score_dir):\n",
    "    os.makedirs(score_dir)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "num_gpu = list(range(torch.cuda.device_count()))\n",
    "\n",
    "vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n",
    "fcn_model = FCN16s(pretrained_net=vgg_model, n_class=n_class)\n",
    "#use_gpu = False\n",
    "if use_gpu:\n",
    "    ts = time.time()\n",
    "    vgg_model = vgg_model.cuda()\n",
    "    fcn_model = fcn_model.cuda()\n",
    "    fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\n",
    "    print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
    "    \n",
    "fcn_model.load_state_dict(torch.load(\"/home/arg/pytorch_fcn/models/ds/virtual.pkl\"))\n",
    "# fcn_model.load_state_dict(torch.load(\"/home/arg/pytorch_fcn/models/ds/style.pkl\"))\n",
    "# fcn_model.load_state_dict(torch.load(\"/home/arg/sis_lab_all/12-1_Pytorch-FCN/models/ds_final/style_transfer.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): FCN16s(\n",
      "    (pretrained_net): VGGNet(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (8): ReLU(inplace=True)\n",
      "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): ReLU(inplace=True)\n",
      "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (13): ReLU(inplace=True)\n",
      "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (15): ReLU(inplace=True)\n",
      "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (18): ReLU(inplace=True)\n",
      "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (20): ReLU(inplace=True)\n",
      "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (22): ReLU(inplace=True)\n",
      "        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (25): ReLU(inplace=True)\n",
      "        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (27): ReLU(inplace=True)\n",
      "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (29): ReLU(inplace=True)\n",
      "        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (deconv2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (deconv3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (deconv4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (deconv5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (classifier): Conv2d(32, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(fcn_model)\n",
    "params = list(fcn_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset class\n",
    "-------------\n",
    "\n",
    "``torch.utils.data.Dataset`` is an abstract class representing a\n",
    "dataset.\n",
    "Your custom dataset should inherit ``Dataset`` and override the following\n",
    "methods:\n",
    "\n",
    "-  ``__len__`` so that ``len(dataset)`` returns the size of the dataset.\n",
    "-  ``__getitem__`` to support the indexing such that ``dataset[i]`` can\n",
    "   be used to get $i$\\ th sample\n",
    "\n",
    "Let's create a dataset class for our face landmarks dataset. We will\n",
    "read the csv in ``__init__`` but leave the reading of images to\n",
    "``__getitem__``. This is memory efficient because all the images are not\n",
    "stored in the memory at once but read as required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "means     = np.array([103.939, 116.779, 123.68]) / 255. # mean of three channels in the order of BGR\n",
    "h, w      = 480, 640\n",
    "val_h     = h\n",
    "val_w     = w\n",
    "class product_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, phase, n_class=n_class, flip_rate=0.):\n",
    "        self.data      = pd.read_csv(csv_file)\n",
    "        self.means     = means\n",
    "        self.n_class   = n_class\n",
    "        self.flip_rate = flip_rate\n",
    "        if phase == 'train':\n",
    "            self.flip_rate = 0.5\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name   = self.data.iloc[idx, 0]\n",
    "        img        = cv2.imread(os.path.join(data_dir, img_name),cv2.IMREAD_UNCHANGED)\n",
    "        label_name = self.data.iloc[idx, 1]\n",
    "        label      = cv2.imread(os.path.join(data_dir, label_name), cv2.IMREAD_GRAYSCALE)\n",
    "        origin_img = img\n",
    "\n",
    "        if random.random() < self.flip_rate:\n",
    "            img   = np.fliplr(img)\n",
    "            label = np.fliplr(label)\n",
    "\n",
    "        # reduce mean\n",
    "#         print(data_dir + img_name)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "        img = img[:, :, ::-1]  # switch to BGR\n",
    "        \n",
    "        img = np.transpose(img, (2, 0, 1)) / 255.\n",
    "        img[0] -= self.means[0]\n",
    "        img[1] -= self.means[1]\n",
    "        img[2] -= self.means[2]\n",
    "\n",
    "        # convert to tensor\n",
    "        img = torch.from_numpy(img.copy()).float()\n",
    "        label = torch.from_numpy(label.copy()).long()\n",
    "\n",
    "        # create one-hot encoding\n",
    "        h, w = label.size()\n",
    "        target = torch.zeros(self.n_class, h, w)\n",
    "        \n",
    "        for index, obj in enumerate(class_list):\n",
    "            if obj in img_name:\n",
    "#                 print index+1, obj\n",
    "                target[index+1][label == 255] = 1\n",
    "                label[label == 255] = index+1\n",
    "\n",
    "        target[0][label == 0] = 1\n",
    " \n",
    "        sample = {'X': img, 'Y': target, 'l': label, 'origin': origin_img}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataloader and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial dataloader for trainning and validation\n",
    "train_file = os.path.join(data_dir, \"train_real_10.csv\")\n",
    "val_file   = os.path.join(data_dir, \"val_real.csv\")\n",
    "train_data = product_dataset(csv_file = train_file, phase = 'train')\n",
    "val_data   = product_dataset(csv_file = val_file, phase = 'val', flip_rate = 0)\n",
    "dataloader = DataLoader(train_data, batch_size = batch_size, shuffle=True, num_workers = 0)\n",
    "val_loader = DataLoader(val_data, batch_size = 5, num_workers = 0)\n",
    "\n",
    "dataiter = iter(val_loader)\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.RMSprop(fcn_model.parameters(), lr = lr, momentum = momentum, weight_decay = w_decay)\n",
    "# decay LR by a factor of 0.5 every step_size = 50 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size = step_size, gamma = gamma)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        fcn_model.train()\n",
    "        scheduler.step()\n",
    "#         configs    = \"FCNs_{}_batch{}_epoch{}_RMSprop_lr{}\"\\\n",
    "#             .format(model_use, batch_size, epoch, lr)\n",
    "        configs    = \"FCNs_{}_epoch{}\".format(model_use, epoch)\n",
    "        model_path = os.path.join(model_dir, configs)\n",
    "        \n",
    "        ts = time.time()\n",
    "        for iter, batch in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = Variable(batch['X'].cuda())\n",
    "                labels = Variable(batch['Y'].cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(batch['X']), Variable(batch['Y'])\n",
    "\n",
    "            outputs = fcn_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch+1, iter, loss.item()))\n",
    "                \n",
    "#             if iter % 2000 == 0:\n",
    "#                 torch.save(fcn_model.state_dict(),model_path + '_'+str(iter)+'.pkl')\n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        torch.save(fcn_model.state_dict(),model_path + '_epoch' + str(epoch) + '.pkl')\n",
    "#         if epoch % 20 == 0:\n",
    "#             torch.save(fcn_model.state_dict(),model_path + '.pkl')\n",
    "\n",
    "        val(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    fcn_model.eval()\n",
    "    TP = np.zeros(n_class-1)\n",
    "    FN = np.zeros(n_class-1)\n",
    "    FP = np.zeros(n_class-1)\n",
    "    total_ious = []\n",
    "    pixel_accs = []\n",
    "    for iter, batch in enumerate(val_loader):\n",
    "        if use_gpu:\n",
    "            inputs = Variable(batch['X'].cuda())\n",
    "        else:\n",
    "            inputs = Variable(batch['X'])\n",
    "\n",
    "        output = fcn_model(inputs)\n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        N, _, h, w = output.shape\n",
    "        pred = output.transpose(0, 2, 3, 1).reshape(-1, n_class).argmax(axis=1).reshape(N, h, w)\n",
    "\n",
    "        target = batch['l'].cpu().numpy().reshape(N, h, w)\n",
    "        for p, t in zip(pred, target):\n",
    "            pixel_accs.append(pixel_acc(p, t))\n",
    "            _TP, _FN, _FP =  analysis(p, t, h, w)\n",
    "            TP += _TP[1:n_class]\n",
    "            FN += _FN[1:n_class]\n",
    "            FP += _FP[1:n_class]\n",
    "            \n",
    "    recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    ious = TP / (TP + FN + FP)\n",
    "    fscore = 2*TP / (2*TP + FN + FP)\n",
    "    total_ious = np.array(total_ious).T  # n_class * val_len\n",
    "    pixel_accs = np.array(pixel_accs).mean()\n",
    "    \n",
    "    np.set_printoptions(formatter=dict(float=lambda t:\"%6.4f\" % t))\n",
    "    print(\"epoch{}, pix_acc: {}, meanIoU: {}, IoUs: {}, recall: {}, precision: {}, fscore: {}\"\\\n",
    "          .format(epoch, pixel_accs, np.nanmean(ious), ious, recall, precision, fscore))\n",
    "    \n",
    "    f1 = open(score_dir + \"/cls_acc_log.txt\",\"a+\")\n",
    "    f1.write('epoch:'+ str(epoch) + ', pix_acc: ' + str(pixel_accs) + '\\n' )\n",
    "    f2 = open(score_dir + \"/cls_iou_log.txt\",\"a+\")\n",
    "    f2.write('epoch:'+ str(epoch) + ', class ious: ' + str(ious) + '\\n' )\n",
    "    f3 = open(score_dir + \"/mean_iou_log.txt\",\"a+\")\n",
    "    f3.write('epoch:'+ str(epoch) + ', mean IoU: ' + str(np.nanmean(ious)) + '\\n' ) \n",
    "    f4 = open(score_dir + \"/recall_log.txt\",\"a+\")\n",
    "    f4.write('epoch:'+ str(epoch) + ', class recall: ' + str(recall) + '\\n' )\n",
    "    f5 = open(score_dir + \"/precision_log.txt\",\"a+\")\n",
    "    f5.write('epoch:'+ str(epoch) + ', class precision: ' + str(precision) + '\\n' )    \n",
    "    f6 = open(score_dir + \"/fscore_log.txt\",\"a+\")\n",
    "    f6.write('epoch:'+ str(epoch) + ', class fscore: ' + str(fscore) + '\\n' )  \n",
    "    \n",
    "\n",
    "def analysis(pred, target, h, w):\n",
    "    # TP, FN, FP, TN\n",
    "    TP = np.zeros(n_class)\n",
    "    FN = np.zeros(n_class)\n",
    "    FP = np.zeros(n_class)\n",
    "\n",
    "    target = target.reshape(h * w)\n",
    "    pred = pred.reshape(h * w)\n",
    "\n",
    "    con_matrix = confusion_matrix(target, pred,labels = np.arange(0,n_class,1))\n",
    "    con_matrix[0][0] = 0\n",
    "    for i in range(0, n_class):\n",
    "        for j in range(0, n_class):\n",
    "            if i == j:\n",
    "                TP[i] += con_matrix[i][j]\n",
    "            if i != j:\n",
    "                FP[j] += con_matrix[i][j]\n",
    "                FN[i] += con_matrix[i][j]\n",
    "    return TP, FN, FP\n",
    "                \n",
    "def pixel_acc(pred, target):\n",
    "    correct = (pred == target).sum()\n",
    "    total   = (target == target).sum()\n",
    "    return float(correct)/float(total)\n",
    "#     return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model_name):\n",
    "    \n",
    "    # load pretrain models\n",
    "    state_dict = torch.load(os.path.join(model_dir, model_name))\n",
    "    fcn_model.load_state_dict(state_dict)\n",
    "    \n",
    "    batch = dataiter.next()\n",
    "    if use_gpu:\n",
    "        inputs = Variable(batch['X'].cuda())\n",
    "    else:\n",
    "        inputs = Variable(batch['X'])\n",
    "    img    = batch['origin'] \n",
    "    label  = batch['l']\n",
    "    \n",
    "    output = fcn_model(inputs)\n",
    "    output = output.data.cpu().numpy()\n",
    "\n",
    "    N, _, h, w = output.shape\n",
    "    pred = output.transpose(0, 2, 3, 1).reshape(-1, n_class).argmax(axis = 1).reshape(N, h, w)\n",
    "\n",
    "    # show images\n",
    "    plt.figure(figsize = (10, 12))\n",
    "    img = img.numpy()\n",
    "    for i in range(N):\n",
    "        img[i] = cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(N, 3, i*3 + 1)\n",
    "        plt.title(\"origin_img\")\n",
    "        plt.imshow(img[i])\n",
    "        #print(np.unique(_img[i]))\n",
    "\n",
    "        plt.subplot(N, 3, i*3 + 2)\n",
    "        plt.title(\"label_img\")\n",
    "        plt.imshow(label[i],cmap = \"brg\",vmin = 0, vmax = n_class - 1)\n",
    "\n",
    "        plt.subplot(N, 3, i*3 + 3)\n",
    "        plt.title(\"prediction\")\n",
    "        plt.imshow(pred[i],cmap = \"brg\",vmin = 0, vmax = n_class - 1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arg/.local/lib/python2.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1, iter0, loss: 0.0386433750391\n",
      "epoch1, iter10, loss: 0.0143192252144\n",
      "epoch1, iter20, loss: 0.0176094584167\n",
      "epoch1, iter30, loss: 0.0131550207734\n",
      "epoch1, iter40, loss: 0.0129877692088\n",
      "epoch1, iter50, loss: 0.0214122068137\n",
      "epoch1, iter60, loss: 0.0132346088067\n",
      "epoch1, iter70, loss: 0.00762546202168\n",
      "epoch1, iter80, loss: 0.0143702523783\n",
      "epoch1, iter90, loss: 0.0191653240472\n",
      "epoch1, iter100, loss: 0.0171561576426\n",
      "epoch1, iter110, loss: 0.0086773512885\n",
      "epoch1, iter120, loss: 0.00865317601711\n",
      "epoch1, iter130, loss: 0.0231681577861\n",
      "epoch1, iter140, loss: 0.0310554131866\n",
      "epoch1, iter150, loss: 0.0198038816452\n",
      "epoch1, iter160, loss: 0.0109806060791\n",
      "epoch1, iter170, loss: 0.0145753966644\n",
      "epoch1, iter180, loss: 0.0146537739784\n",
      "epoch1, iter190, loss: 0.0127118807286\n",
      "epoch1, iter200, loss: 0.0125248050317\n",
      "epoch1, iter210, loss: 0.00450734375045\n",
      "epoch1, iter220, loss: 0.0159170422703\n",
      "epoch1, iter230, loss: 0.00900078285486\n",
      "epoch1, iter240, loss: 0.0082348510623\n",
      "epoch1, iter250, loss: 0.0251687727869\n",
      "epoch1, iter260, loss: 0.00512026343495\n",
      "epoch1, iter270, loss: 0.00788422301412\n",
      "epoch1, iter280, loss: 0.00928833056241\n",
      "epoch1, iter290, loss: 0.00576938083395\n",
      "epoch1, iter300, loss: 0.0215773712844\n",
      "epoch1, iter310, loss: 0.00470800371841\n",
      "epoch1, iter320, loss: 0.00731165194884\n",
      "epoch1, iter330, loss: 0.00877714063972\n",
      "epoch1, iter340, loss: 0.00541309406981\n",
      "epoch1, iter350, loss: 0.00591376703233\n",
      "epoch1, iter360, loss: 0.00856486987323\n",
      "epoch1, iter370, loss: 0.00417894124985\n",
      "epoch1, iter380, loss: 0.00694860471413\n",
      "epoch1, iter390, loss: 0.0122827868909\n",
      "epoch1, iter400, loss: 0.00372919742949\n",
      "epoch1, iter410, loss: 0.013767849654\n",
      "epoch1, iter420, loss: 0.00619564810768\n",
      "epoch1, iter430, loss: 0.00404690299183\n",
      "epoch1, iter440, loss: 0.00346731115133\n",
      "epoch1, iter450, loss: 0.00299078854732\n",
      "epoch1, iter460, loss: 0.00378919974901\n",
      "epoch1, iter470, loss: 0.00888882949948\n",
      "epoch1, iter480, loss: 0.00578297162428\n",
      "epoch1, iter490, loss: 0.00561014562845\n",
      "epoch1, iter500, loss: 0.00523317884654\n",
      "epoch1, iter510, loss: 0.00756039610133\n",
      "epoch1, iter520, loss: 0.0102592352778\n",
      "epoch1, iter530, loss: 0.0180502235889\n",
      "epoch1, iter540, loss: 0.0150521751493\n",
      "epoch1, iter550, loss: 0.00294325104915\n",
      "epoch1, iter560, loss: 0.0106657966971\n",
      "epoch1, iter570, loss: 0.00592572847381\n",
      "epoch1, iter580, loss: 0.00306959892623\n",
      "epoch1, iter590, loss: 0.00596102746204\n",
      "epoch1, iter600, loss: 0.0124938767403\n",
      "epoch1, iter610, loss: 0.00641333358362\n",
      "epoch1, iter620, loss: 0.0180461592972\n",
      "epoch1, iter630, loss: 0.00320914248005\n",
      "epoch1, iter640, loss: 0.00369410961866\n",
      "epoch1, iter650, loss: 0.00256758485921\n",
      "epoch1, iter660, loss: 0.0069883139804\n",
      "epoch1, iter670, loss: 0.011085646227\n",
      "epoch1, iter680, loss: 0.00405335659161\n",
      "epoch1, iter690, loss: 0.00251287803985\n",
      "epoch1, iter700, loss: 0.0167241692543\n",
      "epoch1, iter710, loss: 0.00652203569189\n",
      "Finish epoch 0, time elapsed 303.299546957\n",
      "epoch0, pix_acc: 0.963307241411, meanIoU: 0.469166171395, IoUs: [0.5674 0.1434 0.2749 0.5975 0.3992 0.1962 0.2251 0.7066 0.6406 0.5051\n",
      " 0.0012 0.4498 0.5280 0.7276 0.4509 0.8177 0.6366 0.4344 0.6111 0.4700], recall: [0.5950 0.1550 0.2774 0.6421 0.6120 0.2346 0.2284 0.7507 0.8491 0.5463\n",
      " 0.0012 0.9684 0.5573 0.9419 0.9777 0.9385 0.6485 0.5010 0.7290 0.9256], precision: [0.9245 0.6577 0.9688 0.8958 0.5344 0.5454 0.9400 0.9232 0.7230 0.8701\n",
      " 0.7402 0.4565 0.9095 0.7617 0.4556 0.8640 0.9721 0.7659 0.7906 0.4884], fscore: [0.7240 0.2509 0.4313 0.7480 0.5706 0.3281 0.3675 0.8281 0.7810 0.6712\n",
      " 0.0024 0.6205 0.6911 0.8423 0.6216 0.8997 0.7780 0.6057 0.7586 0.6394]\n",
      "epoch2, iter0, loss: 0.00297897332348\n",
      "epoch2, iter10, loss: 0.00426998920739\n",
      "epoch2, iter20, loss: 0.00490167597309\n",
      "epoch2, iter30, loss: 0.00442009465769\n",
      "epoch2, iter40, loss: 0.00318002537824\n",
      "epoch2, iter50, loss: 0.00501088378951\n",
      "epoch2, iter60, loss: 0.0116102257743\n",
      "epoch2, iter70, loss: 0.00387661089189\n",
      "epoch2, iter80, loss: 0.00130210246425\n",
      "epoch2, iter90, loss: 0.00189771025907\n",
      "epoch2, iter100, loss: 0.00607759226114\n",
      "epoch2, iter110, loss: 0.00692663155496\n",
      "epoch2, iter120, loss: 0.0039384313859\n",
      "epoch2, iter130, loss: 0.00223888270557\n",
      "epoch2, iter140, loss: 0.0118987569585\n",
      "epoch2, iter150, loss: 0.0156087065116\n",
      "epoch2, iter160, loss: 0.00231481203809\n",
      "epoch2, iter170, loss: 0.00410236604512\n",
      "epoch2, iter180, loss: 0.00325916102156\n",
      "epoch2, iter190, loss: 0.00171111081727\n",
      "epoch2, iter200, loss: 0.0051081427373\n",
      "epoch2, iter210, loss: 0.00524917570874\n",
      "epoch2, iter220, loss: 0.00732798455283\n",
      "epoch2, iter230, loss: 0.0034962175414\n",
      "epoch2, iter240, loss: 0.00348694226705\n",
      "epoch2, iter250, loss: 0.00567302014679\n",
      "epoch2, iter260, loss: 0.00276151928119\n",
      "epoch2, iter270, loss: 0.0060899592936\n",
      "epoch2, iter280, loss: 0.0101642375812\n",
      "epoch2, iter290, loss: 0.00171464611776\n",
      "epoch2, iter300, loss: 0.00547504564747\n",
      "epoch2, iter310, loss: 0.00301505066454\n",
      "epoch2, iter320, loss: 0.0133297964931\n",
      "epoch2, iter330, loss: 0.0027331514284\n",
      "epoch2, iter340, loss: 0.0036685061641\n",
      "epoch2, iter350, loss: 0.00303183519281\n",
      "epoch2, iter360, loss: 0.00199958495796\n",
      "epoch2, iter370, loss: 0.00452535413206\n",
      "epoch2, iter380, loss: 0.00347524136305\n",
      "epoch2, iter390, loss: 0.0066612767987\n",
      "epoch2, iter400, loss: 0.00447407597676\n",
      "epoch2, iter410, loss: 0.0016735016834\n",
      "epoch2, iter420, loss: 0.0206492971629\n",
      "epoch2, iter430, loss: 0.00463551701978\n",
      "epoch2, iter440, loss: 0.00796695053577\n",
      "epoch2, iter450, loss: 0.00245745922439\n",
      "epoch2, iter460, loss: 0.0100909331813\n",
      "epoch2, iter470, loss: 0.00191468349658\n",
      "epoch2, iter480, loss: 0.00385963357985\n",
      "epoch2, iter490, loss: 0.00374403549358\n",
      "epoch2, iter500, loss: 0.00843016058207\n",
      "epoch2, iter510, loss: 0.00184014928527\n",
      "epoch2, iter520, loss: 0.00165754498448\n",
      "epoch2, iter530, loss: 0.00127133110072\n",
      "epoch2, iter540, loss: 0.0026797063183\n",
      "epoch2, iter550, loss: 0.00420397287235\n",
      "epoch2, iter560, loss: 0.00373589084484\n",
      "epoch2, iter570, loss: 0.00203695963137\n",
      "epoch2, iter580, loss: 0.0017919986276\n",
      "epoch2, iter590, loss: 0.00408365996554\n",
      "epoch2, iter600, loss: 0.00229169777595\n",
      "epoch2, iter610, loss: 0.0025521973148\n",
      "epoch2, iter620, loss: 0.00167117372621\n",
      "epoch2, iter630, loss: 0.0379064194858\n",
      "epoch2, iter640, loss: 0.00325104082003\n",
      "epoch2, iter650, loss: 0.00409053405747\n",
      "epoch2, iter660, loss: 0.00218879850581\n",
      "epoch2, iter670, loss: 0.00385906384327\n",
      "epoch2, iter680, loss: 0.00331442221068\n",
      "epoch2, iter690, loss: 0.00182514789049\n",
      "epoch2, iter700, loss: 0.00347610213794\n",
      "epoch2, iter710, loss: 0.00310530653223\n",
      "Finish epoch 1, time elapsed 303.603317976\n",
      "epoch1, pix_acc: 0.972784138569, meanIoU: 0.633260235912, IoUs: [0.6188 0.1812 0.6840 0.8508 0.5381 0.4166 0.6158 0.4566 0.8210 0.6673\n",
      " 0.7405 0.5774 0.7329 0.8565 0.8497 0.7996 0.7041 0.4090 0.5478 0.5974], recall: [0.6966 0.2043 0.8004 0.8973 0.5843 0.4241 0.6581 0.7435 0.8683 0.7132\n",
      " 0.7986 0.9775 0.7622 0.9253 0.9726 0.9638 0.7453 0.5771 0.8315 0.6821], precision: [0.8471 0.6156 0.8247 0.9426 0.8721 0.9592 0.9055 0.5420 0.9377 0.9121\n",
      " 0.9104 0.5852 0.9501 0.9201 0.8705 0.8244 0.9273 0.5841 0.6162 0.8279], fscore: [0.7645 0.3068 0.8124 0.9194 0.6997 0.5881 0.7622 0.6270 0.9017 0.8005\n",
      " 0.8509 0.7321 0.8458 0.9227 0.9188 0.8887 0.8264 0.5806 0.7079 0.7480]\n",
      "epoch3, iter0, loss: 0.00386361940764\n",
      "epoch3, iter10, loss: 0.00282105640508\n",
      "epoch3, iter20, loss: 0.0102355089039\n",
      "epoch3, iter30, loss: 0.00329529470764\n",
      "epoch3, iter40, loss: 0.0129142925143\n",
      "epoch3, iter50, loss: 0.00332683254965\n",
      "epoch3, iter60, loss: 0.00637103477493\n",
      "epoch3, iter70, loss: 0.00397274224088\n",
      "epoch3, iter80, loss: 0.00306515512057\n",
      "epoch3, iter90, loss: 0.00523904198781\n",
      "epoch3, iter100, loss: 0.001362986397\n",
      "epoch3, iter110, loss: 0.0233198031783\n",
      "epoch3, iter120, loss: 0.00196014437824\n",
      "epoch3, iter130, loss: 0.00542391417548\n",
      "epoch3, iter140, loss: 0.00129075965378\n",
      "epoch3, iter150, loss: 0.00241031241603\n",
      "epoch3, iter160, loss: 0.00461066747084\n",
      "epoch3, iter170, loss: 0.00178923492786\n",
      "epoch3, iter180, loss: 0.00274106906727\n",
      "epoch3, iter190, loss: 0.00399644020945\n",
      "epoch3, iter200, loss: 0.00158317771275\n",
      "epoch3, iter210, loss: 0.00211266195402\n",
      "epoch3, iter220, loss: 0.00212629185989\n",
      "epoch3, iter230, loss: 0.00535991834477\n",
      "epoch3, iter240, loss: 0.00321631482802\n",
      "epoch3, iter250, loss: 0.00310746370815\n",
      "epoch3, iter260, loss: 0.00351398368366\n",
      "epoch3, iter270, loss: 0.0019230900798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3, iter280, loss: 0.00144000875298\n",
      "epoch3, iter290, loss: 0.0144307194278\n",
      "epoch3, iter300, loss: 0.0061675622128\n",
      "epoch3, iter310, loss: 0.00361498584971\n",
      "epoch3, iter320, loss: 0.00623723678291\n",
      "epoch3, iter330, loss: 0.00355886737816\n",
      "epoch3, iter340, loss: 0.00263846013695\n",
      "epoch3, iter350, loss: 0.00291771860793\n",
      "epoch3, iter360, loss: 0.0022816832643\n",
      "epoch3, iter370, loss: 0.00427305744961\n",
      "epoch3, iter380, loss: 0.00384113634937\n",
      "epoch3, iter390, loss: 0.00165507232305\n",
      "epoch3, iter400, loss: 0.00253339600749\n",
      "epoch3, iter410, loss: 0.00212250370532\n",
      "epoch3, iter420, loss: 0.00258925533853\n",
      "epoch3, iter430, loss: 0.00145778409205\n",
      "epoch3, iter440, loss: 0.0106456167996\n",
      "epoch3, iter450, loss: 0.00309961428866\n",
      "epoch3, iter460, loss: 0.00345535506494\n",
      "epoch3, iter470, loss: 0.00524043943733\n",
      "epoch3, iter480, loss: 0.00959899276495\n",
      "epoch3, iter490, loss: 0.00298907514662\n",
      "epoch3, iter500, loss: 0.00910391658545\n",
      "epoch3, iter510, loss: 0.0092060258612\n",
      "epoch3, iter520, loss: 0.0152346454561\n",
      "epoch3, iter530, loss: 0.00188314577099\n",
      "epoch3, iter540, loss: 0.00907796900719\n",
      "epoch3, iter550, loss: 0.00205055740662\n",
      "epoch3, iter560, loss: 0.00226113549434\n",
      "epoch3, iter570, loss: 0.00255859969184\n",
      "epoch3, iter580, loss: 0.0152468187734\n",
      "epoch3, iter590, loss: 0.0019792788662\n",
      "epoch3, iter600, loss: 0.00327057717368\n",
      "epoch3, iter610, loss: 0.00237658317201\n",
      "epoch3, iter620, loss: 0.00239170342684\n",
      "epoch3, iter630, loss: 0.00344656221569\n",
      "epoch3, iter640, loss: 0.00202210992575\n",
      "epoch3, iter650, loss: 0.00175637612119\n",
      "epoch3, iter660, loss: 0.00219349190593\n",
      "epoch3, iter670, loss: 0.0037203063257\n",
      "epoch3, iter680, loss: 0.00551976310089\n",
      "epoch3, iter690, loss: 0.00618887273595\n",
      "epoch3, iter700, loss: 0.00111573713366\n",
      "epoch3, iter710, loss: 0.0147913498804\n",
      "Finish epoch 2, time elapsed 303.292623997\n",
      "epoch2, pix_acc: 0.964356007858, meanIoU: 0.54514510545, IoUs: [0.4554 0.4527 0.7575 0.7730 0.5468 0.2081 0.4708 0.5005 0.8474 0.6398\n",
      " 0.2973 0.5558 0.7852 0.8535 0.5635 0.4563 0.6392 0.1479 0.7629 0.1894], recall: [0.6605 0.5758 0.7922 0.9251 0.8381 0.2301 0.4869 0.9330 0.9192 0.6842\n",
      " 0.3090 0.9739 0.8397 0.9329 0.7494 0.9587 0.6557 0.1497 0.8354 0.4213], precision: [0.5945 0.6792 0.9454 0.8246 0.6114 0.6853 0.9341 0.5191 0.9156 0.9079\n",
      " 0.8869 0.5642 0.9236 0.9093 0.6943 0.4655 0.9621 0.9259 0.8979 0.2560], fscore: [0.6258 0.6232 0.8620 0.8719 0.7070 0.3445 0.6402 0.6671 0.9174 0.7804\n",
      " 0.4584 0.7145 0.8797 0.9210 0.7208 0.6267 0.7799 0.2578 0.8655 0.3185]\n",
      "epoch4, iter0, loss: 0.00407035741955\n",
      "epoch4, iter10, loss: 0.00277270236984\n",
      "epoch4, iter20, loss: 0.00194535031915\n",
      "epoch4, iter30, loss: 0.0111085809767\n",
      "epoch4, iter40, loss: 0.00144520285539\n",
      "epoch4, iter50, loss: 0.00784922204912\n",
      "epoch4, iter60, loss: 0.00242606853135\n",
      "epoch4, iter70, loss: 0.00342129496858\n",
      "epoch4, iter80, loss: 0.014932337217\n",
      "epoch4, iter90, loss: 0.00122938421555\n",
      "epoch4, iter100, loss: 0.00270566833206\n",
      "epoch4, iter110, loss: 0.00258347205818\n",
      "epoch4, iter120, loss: 0.00104567571543\n",
      "epoch4, iter130, loss: 0.00336110731587\n",
      "epoch4, iter140, loss: 0.00828130170703\n",
      "epoch4, iter150, loss: 0.00147639343049\n",
      "epoch4, iter160, loss: 0.00191447138786\n",
      "epoch4, iter170, loss: 0.00385564751923\n",
      "epoch4, iter180, loss: 0.00551650719717\n",
      "epoch4, iter190, loss: 0.00489252340049\n",
      "epoch4, iter200, loss: 0.00836428813636\n",
      "epoch4, iter210, loss: 0.00142762856558\n",
      "epoch4, iter220, loss: 0.00154379825108\n",
      "epoch4, iter230, loss: 0.00306016509421\n",
      "epoch4, iter240, loss: 0.00219662697054\n",
      "epoch4, iter250, loss: 0.00335311307572\n",
      "epoch4, iter260, loss: 0.00240394985303\n",
      "epoch4, iter270, loss: 0.00231220317073\n",
      "epoch4, iter280, loss: 0.00180339231156\n",
      "epoch4, iter290, loss: 0.00252045551315\n",
      "epoch4, iter300, loss: 0.00286600133404\n",
      "epoch4, iter310, loss: 0.00251694442704\n",
      "epoch4, iter320, loss: 0.002079552738\n",
      "epoch4, iter330, loss: 0.00454584229738\n",
      "epoch4, iter340, loss: 0.00424847006798\n",
      "epoch4, iter350, loss: 0.00229909573682\n",
      "epoch4, iter360, loss: 0.00266682030633\n",
      "epoch4, iter370, loss: 0.00168559339363\n",
      "epoch4, iter380, loss: 0.00441770767793\n",
      "epoch4, iter390, loss: 0.00586762744933\n",
      "epoch4, iter400, loss: 0.00184030691162\n",
      "epoch4, iter410, loss: 0.00181348761544\n",
      "epoch4, iter420, loss: 0.00133154727519\n",
      "epoch4, iter430, loss: 0.00444041471928\n",
      "epoch4, iter440, loss: 0.00147075892892\n",
      "epoch4, iter450, loss: 0.00166129821446\n",
      "epoch4, iter460, loss: 0.00743502704427\n",
      "epoch4, iter470, loss: 0.00210523512214\n",
      "epoch4, iter480, loss: 0.00624506734312\n",
      "epoch4, iter490, loss: 0.00835952721536\n",
      "epoch4, iter500, loss: 0.0060852272436\n",
      "epoch4, iter510, loss: 0.00295379082672\n",
      "epoch4, iter520, loss: 0.00208675255999\n",
      "epoch4, iter530, loss: 0.00180197006557\n",
      "epoch4, iter540, loss: 0.00140674936119\n",
      "epoch4, iter550, loss: 0.00801434181631\n",
      "epoch4, iter560, loss: 0.00930077023804\n",
      "epoch4, iter570, loss: 0.00135557109024\n",
      "epoch4, iter580, loss: 0.00502953352407\n",
      "epoch4, iter590, loss: 0.00173403532244\n",
      "epoch4, iter600, loss: 0.00226368173026\n",
      "epoch4, iter610, loss: 0.00185342994519\n",
      "epoch4, iter620, loss: 0.00265559903346\n",
      "epoch4, iter630, loss: 0.0022698820103\n",
      "epoch4, iter640, loss: 0.00399662181735\n",
      "epoch4, iter650, loss: 0.00591069133952\n",
      "epoch4, iter660, loss: 0.00690213870257\n",
      "epoch4, iter670, loss: 0.00295390211977\n",
      "epoch4, iter680, loss: 0.00100299925543\n",
      "epoch4, iter690, loss: 0.00195497833192\n",
      "epoch4, iter700, loss: 0.00167047057766\n",
      "epoch4, iter710, loss: 0.00172042869963\n",
      "Finish epoch 3, time elapsed 302.705369949\n",
      "epoch3, pix_acc: 0.983686649077, meanIoU: 0.759652227726, IoUs: [0.6396 0.4226 0.7183 0.8276 0.7925 0.7539 0.7171 0.7254 0.8477 0.7232\n",
      " 0.8170 0.7545 0.7828 0.8698 0.8171 0.8817 0.7418 0.8201 0.7198 0.8205], recall: [0.6664 0.4578 0.7441 0.8520 0.8803 0.8470 0.8397 0.9381 0.8771 0.7732\n",
      " 0.8846 0.9769 0.8760 0.9335 0.9771 0.9515 0.7835 0.9183 0.7418 0.8634], precision: [0.9408 0.8463 0.9540 0.9665 0.8881 0.8727 0.8309 0.7619 0.9620 0.9178\n",
      " 0.9144 0.7682 0.8803 0.9272 0.8331 0.9232 0.9332 0.8847 0.9605 0.9429], fscore: [0.7802 0.5941 0.8361 0.9057 0.8842 0.8597 0.8353 0.8409 0.9176 0.8393\n",
      " 0.8993 0.8601 0.8782 0.9303 0.8994 0.9371 0.8518 0.9012 0.8371 0.9014]\n",
      "epoch5, iter0, loss: 0.00253941211849\n",
      "epoch5, iter10, loss: 0.001881586737\n",
      "epoch5, iter20, loss: 0.00141461356543\n",
      "epoch5, iter30, loss: 0.00340852513909\n",
      "epoch5, iter40, loss: 0.00327822589315\n",
      "epoch5, iter50, loss: 0.00108633737545\n",
      "epoch5, iter60, loss: 0.00133533019107\n",
      "epoch5, iter70, loss: 0.00172357261181\n",
      "epoch5, iter80, loss: 0.00227669021115\n",
      "epoch5, iter90, loss: 0.00267426483333\n",
      "epoch5, iter100, loss: 0.0264084860682\n",
      "epoch5, iter110, loss: 0.00299188913777\n",
      "epoch5, iter120, loss: 0.00158167362679\n",
      "epoch5, iter130, loss: 0.00215877103619\n",
      "epoch5, iter140, loss: 0.00338649516925\n",
      "epoch5, iter150, loss: 0.00932138692588\n",
      "epoch5, iter160, loss: 0.00205974187702\n",
      "epoch5, iter170, loss: 0.00161773490254\n",
      "epoch5, iter180, loss: 0.00164715689607\n",
      "epoch5, iter190, loss: 0.0063195428811\n",
      "epoch5, iter200, loss: 0.00241495738737\n",
      "epoch5, iter210, loss: 0.0344776622951\n",
      "epoch5, iter220, loss: 0.0034083223436\n",
      "epoch5, iter230, loss: 0.00230336748064\n",
      "epoch5, iter240, loss: 0.0156008275226\n",
      "epoch5, iter250, loss: 0.00263627967797\n",
      "epoch5, iter260, loss: 0.00436498364434\n",
      "epoch5, iter270, loss: 0.0085078291595\n",
      "epoch5, iter280, loss: 0.00177718978375\n",
      "epoch5, iter290, loss: 0.0026610691566\n",
      "epoch5, iter300, loss: 0.00115745852236\n",
      "epoch5, iter310, loss: 0.00118361774366\n",
      "epoch5, iter320, loss: 0.00362477358431\n",
      "epoch5, iter330, loss: 0.00253376364708\n",
      "epoch5, iter340, loss: 0.00394881051034\n",
      "epoch5, iter350, loss: 0.00193420704454\n",
      "epoch5, iter360, loss: 0.0025072186254\n",
      "epoch5, iter370, loss: 0.00678614992648\n",
      "epoch5, iter380, loss: 0.00129700044636\n",
      "epoch5, iter390, loss: 0.00307437148876\n",
      "epoch5, iter400, loss: 0.00161981442943\n",
      "epoch5, iter410, loss: 0.00101565453224\n",
      "epoch5, iter420, loss: 0.00185571343172\n",
      "epoch5, iter430, loss: 0.00386947649531\n",
      "epoch5, iter440, loss: 0.00143861549441\n",
      "epoch5, iter450, loss: 0.00474583823234\n",
      "epoch5, iter460, loss: 0.00274640321732\n",
      "epoch5, iter470, loss: 0.00225090258755\n",
      "epoch5, iter480, loss: 0.00142612482887\n",
      "epoch5, iter490, loss: 0.0150175010785\n",
      "epoch5, iter500, loss: 0.000760743918363\n",
      "epoch5, iter510, loss: 0.00164887891151\n",
      "epoch5, iter520, loss: 0.00270773703232\n",
      "epoch5, iter530, loss: 0.0017774363514\n",
      "epoch5, iter540, loss: 0.00394601235166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5, iter550, loss: 0.0138836298138\n",
      "epoch5, iter560, loss: 0.00128083210438\n",
      "epoch5, iter570, loss: 0.0038120073732\n",
      "epoch5, iter580, loss: 0.002252911916\n",
      "epoch5, iter590, loss: 0.00487257027999\n",
      "epoch5, iter600, loss: 0.0153174642473\n",
      "epoch5, iter610, loss: 0.00241296109743\n",
      "epoch5, iter620, loss: 0.00387494941242\n",
      "epoch5, iter630, loss: 0.00306069501676\n",
      "epoch5, iter640, loss: 0.00329984677956\n",
      "epoch5, iter650, loss: 0.00133404275402\n",
      "epoch5, iter660, loss: 0.00654144724831\n",
      "epoch5, iter670, loss: 0.00829073973\n",
      "epoch5, iter680, loss: 0.00129140540957\n",
      "epoch5, iter690, loss: 0.000693718728144\n",
      "epoch5, iter700, loss: 0.00153285462875\n",
      "epoch5, iter710, loss: 0.00135851872619\n",
      "Finish epoch 4, time elapsed 303.335637093\n",
      "epoch4, pix_acc: 0.980741865406, meanIoU: 0.723552617948, IoUs: [0.7216 0.3845 0.6561 0.8444 0.8275 0.6778 0.4227 0.7334 0.8569 0.7680\n",
      " 0.8030 0.8048 0.8091 0.8466 0.8572 0.8983 0.7240 0.5519 0.7039 0.5792], recall: [0.7843 0.4016 0.6708 0.9136 0.8648 0.7042 0.4329 0.9278 0.9531 0.8398\n",
      " 0.8423 0.9672 0.8589 0.9341 0.9772 0.9342 0.9194 0.6700 0.9193 0.9395], precision: [0.9003 0.9004 0.9677 0.9176 0.9505 0.9476 0.9469 0.7778 0.8947 0.8999\n",
      " 0.9451 0.8274 0.9332 0.9004 0.8747 0.9589 0.7731 0.7580 0.7502 0.6017], fscore: [0.8383 0.5554 0.7924 0.9156 0.9056 0.8080 0.5942 0.8462 0.9230 0.8688\n",
      " 0.8908 0.8919 0.8945 0.9169 0.9231 0.9464 0.8399 0.7113 0.8262 0.7336]\n",
      "epoch6, iter0, loss: 0.00172047596425\n",
      "epoch6, iter10, loss: 0.00380885461345\n",
      "epoch6, iter20, loss: 0.00979810301214\n",
      "epoch6, iter30, loss: 0.00124085403513\n",
      "epoch6, iter40, loss: 0.00633383728564\n",
      "epoch6, iter50, loss: 0.00224864622578\n",
      "epoch6, iter60, loss: 0.00145129393786\n",
      "epoch6, iter70, loss: 0.0019490250852\n",
      "epoch6, iter80, loss: 0.00178943993524\n",
      "epoch6, iter90, loss: 0.00258314888924\n",
      "epoch6, iter100, loss: 0.00832454487681\n",
      "epoch6, iter110, loss: 0.00186509045307\n",
      "epoch6, iter120, loss: 0.00632719835266\n",
      "epoch6, iter130, loss: 0.0018977537984\n",
      "epoch6, iter140, loss: 0.00241482187994\n",
      "epoch6, iter150, loss: 0.00122871738859\n",
      "epoch6, iter160, loss: 0.00325017096475\n",
      "epoch6, iter170, loss: 0.00578247150406\n",
      "epoch6, iter180, loss: 0.00401653815061\n",
      "epoch6, iter190, loss: 0.00153314648196\n",
      "epoch6, iter200, loss: 0.00171066494659\n",
      "epoch6, iter210, loss: 0.00174626510125\n",
      "epoch6, iter220, loss: 0.00241751689464\n",
      "epoch6, iter230, loss: 0.000953028793447\n",
      "epoch6, iter240, loss: 0.0014946970623\n",
      "epoch6, iter250, loss: 0.00207891594619\n",
      "epoch6, iter260, loss: 0.0043828622438\n",
      "epoch6, iter270, loss: 0.00535878352821\n",
      "epoch6, iter280, loss: 0.00127843231894\n",
      "epoch6, iter290, loss: 0.0021308476571\n",
      "epoch6, iter300, loss: 0.00110089499503\n",
      "epoch6, iter310, loss: 0.00143367948476\n",
      "epoch6, iter320, loss: 0.0175082422793\n",
      "epoch6, iter330, loss: 0.00267555355094\n",
      "epoch6, iter340, loss: 0.00132787763141\n",
      "epoch6, iter350, loss: 0.00400803331286\n",
      "epoch6, iter360, loss: 0.00148767861538\n",
      "epoch6, iter370, loss: 0.00234126159921\n",
      "epoch6, iter380, loss: 0.00743314484134\n",
      "epoch6, iter390, loss: 0.00111845636275\n",
      "epoch6, iter400, loss: 0.0028481988702\n",
      "epoch6, iter410, loss: 0.00293953227811\n",
      "epoch6, iter420, loss: 0.00244144513272\n",
      "epoch6, iter430, loss: 0.00204702839255\n",
      "epoch6, iter440, loss: 0.00207222672179\n",
      "epoch6, iter450, loss: 0.00150719820522\n",
      "epoch6, iter460, loss: 0.00440445309505\n",
      "epoch6, iter470, loss: 0.00172220554668\n",
      "epoch6, iter480, loss: 0.00168767606374\n",
      "epoch6, iter490, loss: 0.00170171819627\n",
      "epoch6, iter500, loss: 0.00377164571546\n",
      "epoch6, iter510, loss: 0.00274689006619\n",
      "epoch6, iter520, loss: 0.00117968325503\n",
      "epoch6, iter530, loss: 0.00991852208972\n",
      "epoch6, iter540, loss: 0.00299868430011\n",
      "epoch6, iter550, loss: 0.00188553822227\n",
      "epoch6, iter560, loss: 0.0027207385283\n",
      "epoch6, iter570, loss: 0.00131041591521\n",
      "epoch6, iter580, loss: 0.00418784329668\n",
      "epoch6, iter590, loss: 0.00474657211453\n",
      "epoch6, iter600, loss: 0.00209600874223\n",
      "epoch6, iter610, loss: 0.00165677175391\n",
      "epoch6, iter620, loss: 0.001215661061\n",
      "epoch6, iter630, loss: 0.00118777644821\n",
      "epoch6, iter640, loss: 0.00297378771938\n",
      "epoch6, iter650, loss: 0.00675204861909\n",
      "epoch6, iter660, loss: 0.00158606865443\n",
      "epoch6, iter670, loss: 0.00128510140348\n",
      "epoch6, iter680, loss: 0.00360758742318\n",
      "epoch6, iter690, loss: 0.00216379249468\n",
      "epoch6, iter700, loss: 0.00257860450074\n",
      "epoch6, iter710, loss: 0.00294342567213\n",
      "Finish epoch 5, time elapsed 303.131099224\n",
      "epoch5, pix_acc: 0.984822090872, meanIoU: 0.793093767403, IoUs: [0.7100 0.5547 0.7708 0.8951 0.7197 0.7529 0.7578 0.7985 0.8789 0.7209\n",
      " 0.8827 0.8970 0.8254 0.8780 0.9067 0.7951 0.7814 0.8247 0.7850 0.7263], recall: [0.7717 0.6015 0.8160 0.9311 0.8841 0.7706 0.8122 0.8261 0.9289 0.7496\n",
      " 0.9284 0.9340 0.9349 0.9079 0.9821 0.9821 0.8164 0.9607 0.9440 0.7399], precision: [0.8989 0.8770 0.9329 0.9586 0.7947 0.9705 0.9189 0.9598 0.9423 0.9496\n",
      " 0.9472 0.9577 0.8757 0.9638 0.9220 0.8068 0.9479 0.8535 0.8233 0.9754], fscore: [0.8304 0.7136 0.8705 0.9446 0.8370 0.8591 0.8622 0.8879 0.9355 0.8378\n",
      " 0.9377 0.9457 0.9043 0.9350 0.9511 0.8859 0.8773 0.9040 0.8795 0.8415]\n",
      "epoch7, iter0, loss: 0.00238314899616\n",
      "epoch7, iter10, loss: 0.00679266639054\n",
      "epoch7, iter20, loss: 0.00276247947477\n",
      "epoch7, iter30, loss: 0.0017645425396\n",
      "epoch7, iter40, loss: 0.00284766615368\n",
      "epoch7, iter50, loss: 0.00331140239723\n",
      "epoch7, iter60, loss: 0.00232773320749\n",
      "epoch7, iter70, loss: 0.00235970295034\n",
      "epoch7, iter80, loss: 0.00144639844075\n",
      "epoch7, iter90, loss: 0.000807388802059\n",
      "epoch7, iter100, loss: 0.00174714066088\n",
      "epoch7, iter110, loss: 0.00278142816387\n",
      "epoch7, iter120, loss: 0.00167239224538\n",
      "epoch7, iter130, loss: 0.00094181165332\n",
      "epoch7, iter140, loss: 0.00119946757331\n",
      "epoch7, iter150, loss: 0.00100576016121\n",
      "epoch7, iter160, loss: 0.00187577598263\n",
      "epoch7, iter170, loss: 0.00152835913468\n",
      "epoch7, iter180, loss: 0.00166350963991\n",
      "epoch7, iter190, loss: 0.00185669818893\n",
      "epoch7, iter200, loss: 0.00242155813612\n",
      "epoch7, iter210, loss: 0.00214356044307\n",
      "epoch7, iter220, loss: 0.002518419642\n",
      "epoch7, iter230, loss: 0.00644843652844\n",
      "epoch7, iter240, loss: 0.00515572074801\n",
      "epoch7, iter250, loss: 0.00156989321113\n",
      "epoch7, iter260, loss: 0.00391575833783\n",
      "epoch7, iter270, loss: 0.00357467541471\n",
      "epoch7, iter280, loss: 0.00130967970472\n",
      "epoch7, iter290, loss: 0.00191898760386\n",
      "epoch7, iter300, loss: 0.00124802417122\n",
      "epoch7, iter310, loss: 0.00192770571448\n",
      "epoch7, iter320, loss: 0.00183399859816\n",
      "epoch7, iter330, loss: 0.00171104364563\n",
      "epoch7, iter340, loss: 0.0063167558983\n",
      "epoch7, iter350, loss: 0.00193570053671\n",
      "epoch7, iter360, loss: 0.00455538230017\n",
      "epoch7, iter370, loss: 0.00189609779045\n",
      "epoch7, iter380, loss: 0.00132864585612\n",
      "epoch7, iter390, loss: 0.0015513098333\n",
      "epoch7, iter400, loss: 0.00151703844313\n",
      "epoch7, iter410, loss: 0.00229170173407\n",
      "epoch7, iter420, loss: 0.00438299449161\n",
      "epoch7, iter430, loss: 0.0107824318111\n",
      "epoch7, iter440, loss: 0.00268881977536\n",
      "epoch7, iter450, loss: 0.0018751838943\n",
      "epoch7, iter460, loss: 0.00340901198797\n",
      "epoch7, iter470, loss: 0.00325705856085\n",
      "epoch7, iter480, loss: 0.00469606369734\n",
      "epoch7, iter490, loss: 0.00229451945052\n",
      "epoch7, iter500, loss: 0.00161229469813\n",
      "epoch7, iter510, loss: 0.00209585111588\n",
      "epoch7, iter520, loss: 0.00162072130479\n",
      "epoch7, iter530, loss: 0.00117731734645\n",
      "epoch7, iter540, loss: 0.00147117674351\n",
      "epoch7, iter550, loss: 0.0056205317378\n",
      "epoch7, iter560, loss: 0.00130080978852\n",
      "epoch7, iter570, loss: 0.00244460604154\n",
      "epoch7, iter580, loss: 0.00494157802314\n",
      "epoch7, iter590, loss: 0.00159450492356\n",
      "epoch7, iter600, loss: 0.00878679007292\n",
      "epoch7, iter610, loss: 0.00114873016719\n",
      "epoch7, iter620, loss: 0.0336399339139\n",
      "epoch7, iter630, loss: 0.00394065771252\n",
      "epoch7, iter640, loss: 0.0115515468642\n",
      "epoch7, iter650, loss: 0.00210967799649\n",
      "epoch7, iter660, loss: 0.00160746125039\n",
      "epoch7, iter670, loss: 0.00162182876375\n",
      "epoch7, iter680, loss: 0.00073554442497\n",
      "epoch7, iter690, loss: 0.00711621437222\n",
      "epoch7, iter700, loss: 0.00183487834875\n",
      "epoch7, iter710, loss: 0.00496188597754\n",
      "Finish epoch 6, time elapsed 303.197278023\n",
      "epoch6, pix_acc: 0.970759066612, meanIoU: 0.646453873715, IoUs: [0.4899 0.5217 0.7742 0.8194 0.7973 0.3753 0.6528 0.7604 0.8830 0.6730\n",
      " 0.8509 0.4366 0.7967 0.8653 0.8438 0.7091 0.6290 0.0230 0.6728 0.3548], recall: [0.8449 0.5555 0.8264 0.8533 0.8424 0.3941 0.6910 0.8406 0.9559 0.7245\n",
      " 0.9067 0.8825 0.8353 0.8882 0.9273 0.7982 0.6380 0.0233 0.9566 0.9388], precision: [0.5383 0.8956 0.9245 0.9538 0.9371 0.8872 0.9218 0.8885 0.9205 0.9046\n",
      " 0.9326 0.4636 0.9452 0.9712 0.9035 0.8639 0.9780 0.6830 0.6940 0.3632], fscore: [0.6576 0.6857 0.8727 0.9007 0.8872 0.5458 0.7899 0.8639 0.9378 0.8046\n",
      " 0.9194 0.6079 0.8869 0.9278 0.9153 0.8298 0.7723 0.0450 0.8044 0.5238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch8, iter0, loss: 0.00220658094622\n",
      "epoch8, iter10, loss: 0.00187102600466\n",
      "epoch8, iter20, loss: 0.0127142472193\n",
      "epoch8, iter30, loss: 0.00218382664025\n",
      "epoch8, iter40, loss: 0.00189127260819\n",
      "epoch8, iter50, loss: 0.00215331534855\n",
      "epoch8, iter60, loss: 0.00117677263916\n",
      "epoch8, iter70, loss: 0.00252917525358\n",
      "epoch8, iter80, loss: 0.00121619715355\n",
      "epoch8, iter90, loss: 0.00250171124935\n",
      "epoch8, iter100, loss: 0.00137780047953\n",
      "epoch8, iter110, loss: 0.00129525968805\n",
      "epoch8, iter120, loss: 0.00112448749132\n",
      "epoch8, iter130, loss: 0.00136910565197\n",
      "epoch8, iter140, loss: 0.00624791579321\n",
      "epoch8, iter150, loss: 0.00142387999222\n",
      "epoch8, iter160, loss: 0.00325898313895\n",
      "epoch8, iter170, loss: 0.00112653360702\n",
      "epoch8, iter180, loss: 0.00145175226498\n",
      "epoch8, iter190, loss: 0.0022593990434\n",
      "epoch8, iter200, loss: 0.0013337720884\n",
      "epoch8, iter210, loss: 0.00204028747976\n",
      "epoch8, iter220, loss: 0.00128184084315\n",
      "epoch8, iter230, loss: 0.00385282165371\n",
      "epoch8, iter240, loss: 0.00259982678108\n",
      "epoch8, iter250, loss: 0.00260729971342\n",
      "epoch8, iter260, loss: 0.00325988279656\n",
      "epoch8, iter270, loss: 0.00101426593028\n",
      "epoch8, iter280, loss: 0.00120255444199\n",
      "epoch8, iter290, loss: 0.00238340464421\n",
      "epoch8, iter300, loss: 0.00216951593757\n",
      "epoch8, iter310, loss: 0.0069804918021\n",
      "epoch8, iter320, loss: 0.00509083922952\n",
      "epoch8, iter330, loss: 0.00192432908807\n",
      "epoch8, iter340, loss: 0.00195444840938\n",
      "epoch8, iter350, loss: 0.00182717072312\n",
      "epoch8, iter360, loss: 0.00205266475677\n",
      "epoch8, iter370, loss: 0.00129967671819\n",
      "epoch8, iter380, loss: 0.00175690930337\n",
      "epoch8, iter390, loss: 0.00310228718445\n",
      "epoch8, iter400, loss: 0.00213961629197\n",
      "epoch8, iter410, loss: 0.00236085639335\n",
      "epoch8, iter420, loss: 0.00165352341719\n",
      "epoch8, iter430, loss: 0.000969863147475\n",
      "epoch8, iter440, loss: 0.00121922022663\n",
      "epoch8, iter450, loss: 0.00274597830139\n",
      "epoch8, iter460, loss: 0.00626675644889\n",
      "epoch8, iter470, loss: 0.00125116098206\n",
      "epoch8, iter480, loss: 0.00160595180932\n",
      "epoch8, iter490, loss: 0.00128548359498\n",
      "epoch8, iter500, loss: 0.00257857819088\n",
      "epoch8, iter510, loss: 0.0017656092532\n",
      "epoch8, iter520, loss: 0.0036217381712\n",
      "epoch8, iter530, loss: 0.00221277144738\n",
      "epoch8, iter540, loss: 0.00643964717165\n",
      "epoch8, iter550, loss: 0.00172843446489\n",
      "epoch8, iter560, loss: 0.00162192084827\n",
      "epoch8, iter570, loss: 0.00335572008044\n",
      "epoch8, iter580, loss: 0.00267904484645\n",
      "epoch8, iter590, loss: 0.00181923178025\n",
      "epoch8, iter600, loss: 0.00169031403493\n",
      "epoch8, iter610, loss: 0.00301105808467\n",
      "epoch8, iter620, loss: 0.00133733800612\n",
      "epoch8, iter630, loss: 0.000724075594917\n",
      "epoch8, iter640, loss: 0.00175639998633\n",
      "epoch8, iter650, loss: 0.00538718793541\n",
      "epoch8, iter660, loss: 0.00170026894193\n",
      "epoch8, iter670, loss: 0.0141440974548\n",
      "epoch8, iter680, loss: 0.00219837646\n",
      "epoch8, iter690, loss: 0.00115314952563\n",
      "epoch8, iter700, loss: 0.00221727462485\n",
      "epoch8, iter710, loss: 0.00141141342465\n",
      "Finish epoch 7, time elapsed 300.82453084\n",
      "epoch7, pix_acc: 0.983040672971, meanIoU: 0.747946490387, IoUs: [0.6905 0.5323 0.8029 0.6276 0.8172 0.8225 0.7377 0.8100 0.9152 0.7187\n",
      " 0.8080 0.8117 0.7855 0.4610 0.8858 0.8888 0.6988 0.6913 0.8079 0.6455], recall: [0.8161 0.6381 0.8563 0.9224 0.8736 0.8755 0.8302 0.8621 0.9545 0.7959\n",
      " 0.8290 0.9766 0.8035 0.4641 0.9744 0.9552 0.7086 0.7771 0.8957 0.8843], precision: [0.8177 0.7625 0.9279 0.6626 0.9267 0.9315 0.8688 0.9306 0.9569 0.8810\n",
      " 0.9695 0.8278 0.9722 0.9858 0.9070 0.9274 0.9806 0.8624 0.8917 0.7050], fscore: [0.8169 0.6948 0.8907 0.7712 0.8994 0.9026 0.8491 0.8950 0.9557 0.8363\n",
      " 0.8938 0.8961 0.8798 0.6311 0.9395 0.9411 0.8227 0.8175 0.8937 0.7846]\n",
      "epoch9, iter0, loss: 0.00128302676603\n",
      "epoch9, iter10, loss: 0.00385274109431\n",
      "epoch9, iter20, loss: 0.00596901634708\n",
      "epoch9, iter30, loss: 0.00103329739068\n",
      "epoch9, iter40, loss: 0.00124421995133\n",
      "epoch9, iter50, loss: 0.00263261725195\n",
      "epoch9, iter60, loss: 0.002687437227\n",
      "epoch9, iter70, loss: 0.00607554707676\n",
      "epoch9, iter80, loss: 0.0388213209808\n",
      "epoch9, iter90, loss: 0.00237511959858\n",
      "epoch9, iter100, loss: 0.0015102479374\n",
      "epoch9, iter110, loss: 0.0025618749205\n",
      "epoch9, iter120, loss: 0.00130561017431\n",
      "epoch9, iter130, loss: 0.00180443073623\n",
      "epoch9, iter140, loss: 0.00181215943303\n",
      "epoch9, iter150, loss: 0.00170474289916\n",
      "epoch9, iter160, loss: 0.00205362844281\n",
      "epoch9, iter170, loss: 0.0139972306788\n",
      "epoch9, iter180, loss: 0.00606648484245\n",
      "epoch9, iter190, loss: 0.00113811064512\n",
      "epoch9, iter200, loss: 0.00309907505289\n",
      "epoch9, iter210, loss: 0.00149445270654\n",
      "epoch9, iter220, loss: 0.00184951454867\n",
      "epoch9, iter230, loss: 0.00161770824343\n",
      "epoch9, iter240, loss: 0.00122182059567\n",
      "epoch9, iter250, loss: 0.00467118574306\n",
      "epoch9, iter260, loss: 0.00133926782291\n",
      "epoch9, iter270, loss: 0.00961053650826\n",
      "epoch9, iter280, loss: 0.00406289054081\n",
      "epoch9, iter290, loss: 0.00111711816862\n",
      "epoch9, iter300, loss: 0.00402595615014\n",
      "epoch9, iter310, loss: 0.00133839948103\n",
      "epoch9, iter320, loss: 0.00202765641734\n",
      "epoch9, iter330, loss: 0.0082963258028\n",
      "epoch9, iter340, loss: 0.00379050383344\n",
      "epoch9, iter350, loss: 0.00322508369572\n",
      "epoch9, iter360, loss: 0.00101868016645\n",
      "epoch9, iter370, loss: 0.00327464495786\n",
      "epoch9, iter380, loss: 0.00342359719798\n",
      "epoch9, iter390, loss: 0.00175216211937\n",
      "epoch9, iter400, loss: 0.00351014710031\n",
      "epoch9, iter410, loss: 0.00101750483736\n",
      "epoch9, iter420, loss: 0.00147939287126\n",
      "epoch9, iter430, loss: 0.00131505157333\n",
      "epoch9, iter440, loss: 0.00208151945844\n",
      "epoch9, iter450, loss: 0.00162994523998\n",
      "epoch9, iter460, loss: 0.00363796995953\n",
      "epoch9, iter470, loss: 0.00279612001032\n",
      "epoch9, iter480, loss: 0.00139487499837\n",
      "epoch9, iter490, loss: 0.0021424673032\n",
      "epoch9, iter500, loss: 0.00135711149778\n",
      "epoch9, iter510, loss: 0.00150901137386\n",
      "epoch9, iter520, loss: 0.00319042685442\n",
      "epoch9, iter530, loss: 0.00229470874183\n",
      "epoch9, iter540, loss: 0.0169460102916\n",
      "epoch9, iter550, loss: 0.00224145501852\n",
      "epoch9, iter560, loss: 0.0049007195048\n",
      "epoch9, iter570, loss: 0.00216701510362\n",
      "epoch9, iter580, loss: 0.00153000780847\n",
      "epoch9, iter590, loss: 0.00130502774846\n",
      "epoch9, iter600, loss: 0.0024723992683\n",
      "epoch9, iter610, loss: 0.000728891987819\n",
      "epoch9, iter620, loss: 0.00263394508511\n",
      "epoch9, iter630, loss: 0.0029300537426\n",
      "epoch9, iter640, loss: 0.00148864078801\n",
      "epoch9, iter650, loss: 0.00130682904273\n",
      "epoch9, iter660, loss: 0.00154860597104\n",
      "epoch9, iter670, loss: 0.00155818113126\n",
      "epoch9, iter680, loss: 0.00355045637116\n",
      "epoch9, iter690, loss: 0.00292049814016\n",
      "epoch9, iter700, loss: 0.00451373541728\n",
      "epoch9, iter710, loss: 0.00482690846547\n",
      "Finish epoch 8, time elapsed 326.860618114\n",
      "epoch8, pix_acc: 0.983566617553, meanIoU: 0.755376400446, IoUs: [0.3728 0.4924 0.7710 0.8415 0.8318 0.8406 0.4096 0.5658 0.9121 0.7666\n",
      " 0.8333 0.8615 0.8237 0.8947 0.9333 0.8811 0.7280 0.7823 0.7108 0.8545], recall: [0.3805 0.6586 0.8482 0.9362 0.9216 0.9204 0.4249 0.9439 0.9663 0.8044\n",
      " 0.8654 0.9688 0.9108 0.9412 0.9695 0.9623 0.7778 0.9768 0.7638 0.8733], precision: [0.9485 0.6613 0.8944 0.8927 0.8952 0.9065 0.9192 0.5855 0.9421 0.9422\n",
      " 0.9573 0.8861 0.8961 0.9477 0.9615 0.9126 0.9191 0.7971 0.9111 0.9754], fscore: [0.5431 0.6599 0.8707 0.9139 0.9082 0.9134 0.5811 0.7227 0.9540 0.8679\n",
      " 0.9091 0.9256 0.9034 0.9444 0.9655 0.9368 0.8426 0.8779 0.8310 0.9215]\n",
      "epoch10, iter0, loss: 0.00372349447571\n",
      "epoch10, iter10, loss: 0.0096102328971\n",
      "epoch10, iter20, loss: 0.00643769139424\n",
      "epoch10, iter30, loss: 0.00142160162795\n",
      "epoch10, iter40, loss: 0.0305115263909\n",
      "epoch10, iter50, loss: 0.00783107336611\n",
      "epoch10, iter60, loss: 0.00219151936471\n",
      "epoch10, iter70, loss: 0.00261184130795\n",
      "epoch10, iter80, loss: 0.00131228344981\n",
      "epoch10, iter90, loss: 0.00102210626937\n",
      "epoch10, iter100, loss: 0.00202904432081\n",
      "epoch10, iter110, loss: 0.000835783837829\n",
      "epoch10, iter120, loss: 0.00100379739888\n",
      "epoch10, iter130, loss: 0.00517806969583\n",
      "epoch10, iter140, loss: 0.00687441602349\n",
      "epoch10, iter150, loss: 0.00133856816683\n",
      "epoch10, iter160, loss: 0.00307071977295\n",
      "epoch10, iter170, loss: 0.0023854887113\n",
      "epoch10, iter180, loss: 0.00427905004472\n",
      "epoch10, iter190, loss: 0.00451741134748\n",
      "epoch10, iter200, loss: 0.00267857010476\n",
      "epoch10, iter210, loss: 0.00357931386679\n",
      "epoch10, iter220, loss: 0.0014994381927\n",
      "epoch10, iter230, loss: 0.00223795906641\n",
      "epoch10, iter240, loss: 0.00170264404733\n",
      "epoch10, iter250, loss: 0.00265764561482\n",
      "epoch10, iter260, loss: 0.0039165657945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch10, iter270, loss: 0.0026807480026\n",
      "epoch10, iter280, loss: 0.00262762000784\n",
      "epoch10, iter290, loss: 0.00102209602483\n",
      "epoch10, iter300, loss: 0.00359611283056\n",
      "epoch10, iter310, loss: 0.00126878125593\n",
      "epoch10, iter320, loss: 0.00146458216477\n",
      "epoch10, iter330, loss: 0.00132545712404\n",
      "epoch10, iter340, loss: 0.00180875312071\n",
      "epoch10, iter350, loss: 0.00216083158739\n",
      "epoch10, iter360, loss: 0.00159764604177\n",
      "epoch10, iter370, loss: 0.00140639930032\n",
      "epoch10, iter380, loss: 0.00108785787597\n",
      "epoch10, iter390, loss: 0.0121378358454\n",
      "epoch10, iter400, loss: 0.000962217396591\n",
      "epoch10, iter410, loss: 0.00199215649627\n",
      "epoch10, iter420, loss: 0.0144368736073\n",
      "epoch10, iter430, loss: 0.00170910020825\n",
      "epoch10, iter440, loss: 0.00199682358652\n",
      "epoch10, iter450, loss: 0.00429882109165\n",
      "epoch10, iter460, loss: 0.000957680458669\n",
      "epoch10, iter470, loss: 0.000979012693278\n",
      "epoch10, iter480, loss: 0.00126964575611\n",
      "epoch10, iter490, loss: 0.0016465683002\n",
      "epoch10, iter500, loss: 0.00121052342001\n",
      "epoch10, iter510, loss: 0.00663854181767\n",
      "epoch10, iter520, loss: 0.00463460991159\n",
      "epoch10, iter530, loss: 0.00415638322011\n",
      "epoch10, iter540, loss: 0.00160239078104\n",
      "epoch10, iter550, loss: 0.00216500647366\n",
      "epoch10, iter560, loss: 0.00234850635752\n",
      "epoch10, iter570, loss: 0.00152068748139\n",
      "epoch10, iter580, loss: 0.00118716422003\n",
      "epoch10, iter590, loss: 0.00199502939358\n",
      "epoch10, iter600, loss: 0.00162941997405\n",
      "epoch10, iter610, loss: 0.000982027966529\n",
      "epoch10, iter620, loss: 0.00204043556005\n",
      "epoch10, iter630, loss: 0.00180195365101\n",
      "epoch10, iter640, loss: 0.00204671709798\n",
      "epoch10, iter650, loss: 0.0022541761864\n",
      "epoch10, iter660, loss: 0.0019561201334\n",
      "epoch10, iter670, loss: 0.00227693840861\n",
      "epoch10, iter680, loss: 0.0133277634159\n",
      "epoch10, iter690, loss: 0.00187762337737\n",
      "epoch10, iter700, loss: 0.00323915202171\n",
      "epoch10, iter710, loss: 0.00519898533821\n",
      "Finish epoch 9, time elapsed 304.493177176\n",
      "epoch9, pix_acc: 0.980958453262, meanIoU: 0.736094167991, IoUs: [0.6586 0.5449 0.6415 0.8933 0.6406 0.3297 0.7366 0.6913 0.8999 0.7336\n",
      " 0.8304 0.6447 0.7087 0.8981 0.7348 0.8289 0.7975 0.8462 0.7696 0.8928], recall: [0.6942 0.5768 0.8476 0.9206 0.9028 0.3343 0.8070 0.9244 0.9520 0.8385\n",
      " 0.8588 0.9814 0.9216 0.9445 0.9807 0.9634 0.8245 0.8759 0.8390 0.9417], precision: [0.9278 0.9079 0.7252 0.9678 0.6881 0.9603 0.8942 0.7328 0.9426 0.8543\n",
      " 0.9617 0.6526 0.7541 0.9482 0.7455 0.8559 0.9605 0.9615 0.9030 0.9450], fscore: [0.7942 0.7055 0.7816 0.9437 0.7810 0.4959 0.8483 0.8175 0.9473 0.8463\n",
      " 0.9074 0.7839 0.8295 0.9463 0.8471 0.9065 0.8874 0.9167 0.8698 0.9434]\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1, iter0, loss: 0.0563288070261\n",
      "epoch1, iter10, loss: 0.0224344339222\n",
      "epoch1, iter20, loss: 0.0221008881927\n",
      "epoch1, iter30, loss: 0.00708737364039\n",
      "epoch1, iter40, loss: 0.0163025986403\n",
      "epoch1, iter50, loss: 0.014272400178\n",
      "epoch1, iter60, loss: 0.00992776174098\n",
      "epoch1, iter70, loss: 0.00511758495122\n",
      "epoch1, iter80, loss: 0.024222208187\n",
      "epoch1, iter90, loss: 0.0121217146516\n",
      "epoch1, iter100, loss: 0.00465448433533\n",
      "epoch1, iter110, loss: 0.00318821961991\n",
      "epoch1, iter120, loss: 0.00474179163575\n",
      "epoch1, iter130, loss: 0.00451340992004\n",
      "epoch1, iter140, loss: 0.0123002380133\n",
      "epoch1, iter150, loss: 0.00865159276873\n",
      "epoch1, iter160, loss: 0.00523022701964\n",
      "epoch1, iter170, loss: 0.00528397923335\n",
      "epoch1, iter180, loss: 0.0134360743687\n",
      "epoch1, iter190, loss: 0.0156902521849\n",
      "epoch1, iter200, loss: 0.0139035927132\n",
      "epoch1, iter210, loss: 0.00440478604287\n",
      "epoch1, iter220, loss: 0.00593716744334\n",
      "epoch1, iter230, loss: 0.00640032067895\n",
      "epoch1, iter240, loss: 0.00415230635554\n",
      "epoch1, iter250, loss: 0.00736215338111\n",
      "epoch1, iter260, loss: 0.00301335728727\n",
      "epoch1, iter270, loss: 0.00854208320379\n",
      "epoch1, iter280, loss: 0.0121616879478\n",
      "epoch1, iter290, loss: 0.00521013746038\n",
      "epoch1, iter300, loss: 0.00388617813587\n",
      "epoch1, iter310, loss: 0.00402418011799\n",
      "epoch1, iter320, loss: 0.0164285618812\n",
      "epoch1, iter330, loss: 0.00507950410247\n",
      "epoch1, iter340, loss: 0.00484262686223\n",
      "epoch1, iter350, loss: 0.00361979263835\n",
      "epoch1, iter360, loss: 0.0062944246456\n",
      "epoch1, iter370, loss: 0.00251187384129\n",
      "epoch1, iter380, loss: 0.00218449975364\n",
      "epoch1, iter390, loss: 0.00430933199823\n",
      "epoch1, iter400, loss: 0.00477456953377\n",
      "epoch1, iter410, loss: 0.00578825408593\n",
      "epoch1, iter420, loss: 0.00379751459695\n",
      "epoch1, iter430, loss: 0.00316827720962\n",
      "epoch1, iter440, loss: 0.00903522409499\n",
      "epoch1, iter450, loss: 0.0147939743474\n",
      "epoch1, iter460, loss: 0.00448348233476\n",
      "epoch1, iter470, loss: 0.0027480206918\n",
      "epoch1, iter480, loss: 0.00212519732304\n",
      "epoch1, iter490, loss: 0.00654846429825\n",
      "epoch1, iter500, loss: 0.00224856985733\n",
      "epoch1, iter510, loss: 0.00694309500977\n",
      "epoch1, iter520, loss: 0.00640806090087\n",
      "epoch1, iter530, loss: 0.00567756081\n",
      "epoch1, iter540, loss: 0.0028504843358\n",
      "epoch1, iter550, loss: 0.0119600538164\n",
      "epoch1, iter560, loss: 0.00336784403771\n",
      "epoch1, iter570, loss: 0.0161210913211\n",
      "epoch1, iter580, loss: 0.00129843270406\n",
      "epoch1, iter590, loss: 0.00555351190269\n",
      "epoch1, iter600, loss: 0.00416454253718\n",
      "epoch1, iter610, loss: 0.00594882760197\n",
      "epoch1, iter620, loss: 0.00667517026886\n",
      "epoch1, iter630, loss: 0.00572772650048\n",
      "epoch1, iter640, loss: 0.00511253578588\n",
      "epoch1, iter650, loss: 0.0173853598535\n",
      "epoch1, iter660, loss: 0.00352477654815\n",
      "epoch1, iter670, loss: 0.00158360798378\n",
      "epoch1, iter680, loss: 0.00462412415072\n",
      "epoch1, iter690, loss: 0.00180948071647\n",
      "epoch1, iter700, loss: 0.00283437687904\n",
      "epoch1, iter710, loss: 0.0259380079806\n",
      "Finish epoch 0, time elapsed 303.633501053\n",
      "epoch0, pix_acc: 0.962978405976, meanIoU: 0.498215661408, IoUs: [0.5629 0.3906 0.4276 0.6378 0.4192 0.6191 0.4950 0.6741 0.5853 0.5868\n",
      " 0.4894 0.1802 0.6995 0.8269 0.5822 0.6006 0.4317 0.0862 0.3673 0.3016], recall: [0.6171 0.4161 0.4403 0.8905 0.8048 0.7043 0.7440 0.6957 0.8887 0.6364\n",
      " 0.9176 0.1829 0.7760 0.8529 0.5950 0.8966 0.4515 0.0874 0.9574 0.6442], precision: [0.8650 0.8643 0.9368 0.6921 0.4667 0.8366 0.5967 0.9561 0.6316 0.8829\n",
      " 0.5119 0.9259 0.8765 0.9645 0.9643 0.6453 0.9078 0.8665 0.3734 0.3619], fscore: [0.7203 0.5618 0.5990 0.7788 0.5908 0.7648 0.6623 0.8054 0.7384 0.7396\n",
      " 0.6572 0.3054 0.8232 0.9053 0.7359 0.7505 0.6031 0.1588 0.5373 0.4634]\n",
      "epoch2, iter0, loss: 0.00136308965739\n",
      "epoch2, iter10, loss: 0.00199298770167\n",
      "epoch2, iter20, loss: 0.00329852267168\n",
      "epoch2, iter30, loss: 0.00334648485295\n",
      "epoch2, iter40, loss: 0.00165844045114\n",
      "epoch2, iter50, loss: 0.00158464245033\n",
      "epoch2, iter60, loss: 0.00191990856547\n",
      "epoch2, iter70, loss: 0.00223934045061\n",
      "epoch2, iter80, loss: 0.00612377794459\n",
      "epoch2, iter90, loss: 0.00379219395109\n",
      "epoch2, iter100, loss: 0.00158095441293\n",
      "epoch2, iter110, loss: 0.00478301523253\n",
      "epoch2, iter120, loss: 0.00659336475655\n",
      "epoch2, iter130, loss: 0.00294782407582\n",
      "epoch2, iter140, loss: 0.00242490856908\n",
      "epoch2, iter150, loss: 0.00359036889859\n",
      "epoch2, iter160, loss: 0.00151826068759\n",
      "epoch2, iter170, loss: 0.00336954253726\n",
      "epoch2, iter180, loss: 0.00464493362233\n",
      "epoch2, iter190, loss: 0.00573904719204\n",
      "epoch2, iter200, loss: 0.0092670340091\n",
      "epoch2, iter210, loss: 0.00345944217406\n",
      "epoch2, iter220, loss: 0.00730614829808\n",
      "epoch2, iter230, loss: 0.00256635388359\n",
      "epoch2, iter240, loss: 0.00104460830335\n",
      "epoch2, iter250, loss: 0.00442148093134\n",
      "epoch2, iter260, loss: 0.00150230678264\n",
      "epoch2, iter270, loss: 0.00556741980836\n",
      "epoch2, iter280, loss: 0.00368573074229\n",
      "epoch2, iter290, loss: 0.00457260617986\n",
      "epoch2, iter300, loss: 0.00180851912592\n",
      "epoch2, iter310, loss: 0.00397343281657\n",
      "epoch2, iter320, loss: 0.00350773683749\n",
      "epoch2, iter330, loss: 0.0260513294488\n",
      "epoch2, iter340, loss: 0.00826563220471\n",
      "epoch2, iter350, loss: 0.00674084527418\n",
      "epoch2, iter360, loss: 0.00531402276829\n",
      "epoch2, iter370, loss: 0.00458663562313\n",
      "epoch2, iter380, loss: 0.0178562160581\n",
      "epoch2, iter390, loss: 0.00289303506725\n",
      "epoch2, iter400, loss: 0.00671091908589\n",
      "epoch2, iter410, loss: 0.00559948477894\n",
      "epoch2, iter420, loss: 0.0100014694035\n",
      "epoch2, iter430, loss: 0.00484902877361\n",
      "epoch2, iter440, loss: 0.012825883925\n",
      "epoch2, iter450, loss: 0.00186970958021\n",
      "epoch2, iter460, loss: 0.00375846610405\n",
      "epoch2, iter470, loss: 0.00312927179039\n",
      "epoch2, iter480, loss: 0.00308309262618\n",
      "epoch2, iter490, loss: 0.00655679591\n",
      "epoch2, iter500, loss: 0.00115693861153\n",
      "epoch2, iter510, loss: 0.00441886112094\n",
      "epoch2, iter520, loss: 0.00431497907266\n",
      "epoch2, iter530, loss: 0.00764520280063\n",
      "epoch2, iter540, loss: 0.00694234296679\n",
      "epoch2, iter550, loss: 0.00396920274943\n",
      "epoch2, iter560, loss: 0.00246301433071\n",
      "epoch2, iter570, loss: 0.00320086535066\n",
      "epoch2, iter580, loss: 0.0189593303949\n",
      "epoch2, iter590, loss: 0.00322072696872\n",
      "epoch2, iter600, loss: 0.00317416642793\n",
      "epoch2, iter610, loss: 0.00215612747706\n",
      "epoch2, iter620, loss: 0.00194685789756\n",
      "epoch2, iter630, loss: 0.00324081582949\n",
      "epoch2, iter640, loss: 0.00181960361078\n",
      "epoch2, iter650, loss: 0.00210636504926\n",
      "epoch2, iter660, loss: 0.016027232632\n",
      "epoch2, iter670, loss: 0.00555147835985\n",
      "epoch2, iter680, loss: 0.0108134709299\n",
      "epoch2, iter690, loss: 0.00275422562845\n",
      "epoch2, iter700, loss: 0.00548302894458\n",
      "epoch2, iter710, loss: 0.00213168491609\n",
      "Finish epoch 1, time elapsed 303.440798998\n",
      "epoch1, pix_acc: 0.978672652823, meanIoU: 0.698829875429, IoUs: [0.6243 0.3462 0.6942 0.8670 0.6428 0.7617 0.6692 0.6255 0.7770 0.6981\n",
      " 0.8130 0.8243 0.6875 0.8915 0.9297 0.8653 0.6771 0.5100 0.5233 0.5487], recall: [0.7830 0.3611 0.7411 0.8915 0.8623 0.7799 0.7162 0.9258 0.8338 0.7319\n",
      " 0.8702 0.9023 0.7140 0.9283 0.9620 0.9208 0.7658 0.5273 0.8294 0.9560], precision: [0.7550 0.8938 0.9165 0.9693 0.7163 0.9703 0.9107 0.6585 0.9194 0.9380\n",
      " 0.9252 0.9052 0.9487 0.9575 0.9652 0.9349 0.8540 0.9395 0.5864 0.5630], fscore: [0.7687 0.5144 0.8195 0.9288 0.7825 0.8647 0.8019 0.7696 0.8745 0.8222\n",
      " 0.8969 0.9037 0.8148 0.9426 0.9636 0.9278 0.8075 0.6755 0.6871 0.7086]\n",
      "epoch3, iter0, loss: 0.00507823796943\n",
      "epoch3, iter10, loss: 0.00424634385854\n",
      "epoch3, iter20, loss: 0.00279930280522\n",
      "epoch3, iter30, loss: 0.00141758529935\n",
      "epoch3, iter40, loss: 0.00651246169582\n",
      "epoch3, iter50, loss: 0.00235086213797\n",
      "epoch3, iter60, loss: 0.00412538740784\n",
      "epoch3, iter70, loss: 0.00409418297932\n",
      "epoch3, iter80, loss: 0.00383791769855\n",
      "epoch3, iter90, loss: 0.00427885353565\n",
      "epoch3, iter100, loss: 0.00205444428138\n",
      "epoch3, iter110, loss: 0.00315336673521\n",
      "epoch3, iter120, loss: 0.0037957187742\n",
      "epoch3, iter130, loss: 0.00673058116809\n",
      "epoch3, iter140, loss: 0.00346001191065\n",
      "epoch3, iter150, loss: 0.0138948727399\n",
      "epoch3, iter160, loss: 0.00209617218934\n",
      "epoch3, iter170, loss: 0.00569889694452\n",
      "epoch3, iter180, loss: 0.00198173359968\n",
      "epoch3, iter190, loss: 0.00358548434451\n",
      "epoch3, iter200, loss: 0.00524922972545\n",
      "epoch3, iter210, loss: 0.00259705982171\n",
      "epoch3, iter220, loss: 0.00165767909493\n",
      "epoch3, iter230, loss: 0.00319028738886\n",
      "epoch3, iter240, loss: 0.0124412160367\n",
      "epoch3, iter250, loss: 0.0122702987865\n",
      "epoch3, iter260, loss: 0.00205788132735\n",
      "epoch3, iter270, loss: 0.00234150304459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3, iter280, loss: 0.00145780621096\n",
      "epoch3, iter290, loss: 0.00109176326077\n",
      "epoch3, iter300, loss: 0.00351006747223\n",
      "epoch3, iter310, loss: 0.00175159785431\n",
      "epoch3, iter320, loss: 0.00462011294439\n",
      "epoch3, iter330, loss: 0.00234081386589\n",
      "epoch3, iter340, loss: 0.00176623626612\n",
      "epoch3, iter350, loss: 0.00266714044847\n",
      "epoch3, iter360, loss: 0.00190440029837\n",
      "epoch3, iter370, loss: 0.00245703454129\n",
      "epoch3, iter380, loss: 0.00194424577057\n",
      "epoch3, iter390, loss: 0.00204485980794\n",
      "epoch3, iter400, loss: 0.00112432485912\n",
      "epoch3, iter410, loss: 0.00205363566056\n",
      "epoch3, iter420, loss: 0.00321929622442\n",
      "epoch3, iter430, loss: 0.00444630905986\n",
      "epoch3, iter440, loss: 0.00157359847799\n",
      "epoch3, iter450, loss: 0.00610102666542\n",
      "epoch3, iter460, loss: 0.00163529801648\n",
      "epoch3, iter470, loss: 0.00122560025193\n",
      "epoch3, iter480, loss: 0.00156719656661\n",
      "epoch3, iter490, loss: 0.00331062613986\n",
      "epoch3, iter500, loss: 0.00110161560588\n",
      "epoch3, iter510, loss: 0.00671135168523\n",
      "epoch3, iter520, loss: 0.00613532867283\n",
      "epoch3, iter530, loss: 0.00905065145344\n",
      "epoch3, iter540, loss: 0.00242741825059\n",
      "epoch3, iter550, loss: 0.00189043139108\n",
      "epoch3, iter560, loss: 0.00148510211147\n",
      "epoch3, iter570, loss: 0.00738452095538\n",
      "epoch3, iter580, loss: 0.00981431268156\n",
      "epoch3, iter590, loss: 0.00255159800872\n",
      "epoch3, iter600, loss: 0.00430658645928\n",
      "epoch3, iter610, loss: 0.000991889508441\n",
      "epoch3, iter620, loss: 0.00168030930217\n",
      "epoch3, iter630, loss: 0.00318961567245\n",
      "epoch3, iter640, loss: 0.00273805577308\n",
      "epoch3, iter650, loss: 0.00116088381037\n",
      "epoch3, iter660, loss: 0.00157645065337\n",
      "epoch3, iter670, loss: 0.00327704986557\n",
      "epoch3, iter680, loss: 0.00325504713692\n",
      "epoch3, iter690, loss: 0.0270127970725\n",
      "epoch3, iter700, loss: 0.00362363038585\n",
      "epoch3, iter710, loss: 0.00290941190906\n",
      "Finish epoch 2, time elapsed 302.286212921\n",
      "epoch2, pix_acc: 0.979341856268, meanIoU: 0.715873218883, IoUs: [0.5000 0.4523 0.7410 0.8684 0.5920 0.6733 0.7211 0.6939 0.8539 0.7613\n",
      " 0.5423 0.6793 0.8232 0.8648 0.7888 0.7582 0.7331 0.8304 0.6529 0.7872], recall: [0.8049 0.4733 0.7776 0.9124 0.7147 0.6884 0.7861 0.9043 0.8864 0.8206\n",
      " 0.5531 0.9883 0.8702 0.9171 0.9707 0.8250 0.8884 0.9486 0.9310 0.9532], precision: [0.5690 0.9106 0.9402 0.9474 0.7752 0.9686 0.8971 0.7488 0.9588 0.9134\n",
      " 0.9654 0.6848 0.9384 0.9381 0.8080 0.9035 0.8074 0.8695 0.6861 0.8189], fscore: [0.6667 0.6229 0.8512 0.9295 0.7437 0.8048 0.8379 0.8193 0.9212 0.8645\n",
      " 0.7032 0.8090 0.9030 0.9275 0.8819 0.8625 0.8460 0.9074 0.7900 0.8809]\n",
      "epoch4, iter0, loss: 0.00463690096512\n",
      "epoch4, iter10, loss: 0.00151569757145\n",
      "epoch4, iter20, loss: 0.00179600925185\n",
      "epoch4, iter30, loss: 0.0022058468312\n",
      "epoch4, iter40, loss: 0.00187464104965\n",
      "epoch4, iter50, loss: 0.0037059718743\n",
      "epoch4, iter60, loss: 0.00170247606002\n",
      "epoch4, iter70, loss: 0.00206273817457\n",
      "epoch4, iter80, loss: 0.00100592419039\n",
      "epoch4, iter90, loss: 0.00120752421208\n",
      "epoch4, iter100, loss: 0.00190699822269\n",
      "epoch4, iter110, loss: 0.00225309282541\n",
      "epoch4, iter120, loss: 0.00277484068647\n",
      "epoch4, iter130, loss: 0.00149664725177\n",
      "epoch4, iter140, loss: 0.00200275145471\n",
      "epoch4, iter150, loss: 0.00140989688225\n",
      "epoch4, iter160, loss: 0.00415575318038\n",
      "epoch4, iter170, loss: 0.00603453163058\n",
      "epoch4, iter180, loss: 0.0016324496828\n",
      "epoch4, iter190, loss: 0.00453769695014\n",
      "epoch4, iter200, loss: 0.00192676414736\n",
      "epoch4, iter210, loss: 0.00273159681819\n",
      "epoch4, iter220, loss: 0.0015027821064\n",
      "epoch4, iter230, loss: 0.00135275279172\n",
      "epoch4, iter240, loss: 0.00291824899614\n",
      "epoch4, iter250, loss: 0.00175275944639\n",
      "epoch4, iter260, loss: 0.0034880717285\n",
      "epoch4, iter270, loss: 0.0269543975592\n",
      "epoch4, iter280, loss: 0.00196342053823\n",
      "epoch4, iter290, loss: 0.00180954427924\n",
      "epoch4, iter300, loss: 0.00200914102606\n",
      "epoch4, iter310, loss: 0.00233086501248\n",
      "epoch4, iter320, loss: 0.00275749852881\n",
      "epoch4, iter330, loss: 0.00402200920507\n",
      "epoch4, iter340, loss: 0.00171221396886\n",
      "epoch4, iter350, loss: 0.00161195511464\n",
      "epoch4, iter360, loss: 0.00246861041524\n",
      "epoch4, iter370, loss: 0.00139724288601\n",
      "epoch4, iter380, loss: 0.00938501488417\n",
      "epoch4, iter390, loss: 0.0026429456193\n",
      "epoch4, iter400, loss: 0.00188487186097\n",
      "epoch4, iter410, loss: 0.00200377800502\n",
      "epoch4, iter420, loss: 0.0062565356493\n",
      "epoch4, iter430, loss: 0.00188246520702\n",
      "epoch4, iter440, loss: 0.00241106329486\n",
      "epoch4, iter450, loss: 0.00637922482565\n",
      "epoch4, iter460, loss: 0.00417315028608\n",
      "epoch4, iter470, loss: 0.00359295634553\n",
      "epoch4, iter480, loss: 0.00458243861794\n",
      "epoch4, iter490, loss: 0.00166835624259\n",
      "epoch4, iter500, loss: 0.00213442370296\n",
      "epoch4, iter510, loss: 0.00630886852741\n",
      "epoch4, iter520, loss: 0.00248350366019\n",
      "epoch4, iter530, loss: 0.0131938625127\n",
      "epoch4, iter540, loss: 0.0023520453833\n",
      "epoch4, iter550, loss: 0.00194944324903\n",
      "epoch4, iter560, loss: 0.00236768135801\n",
      "epoch4, iter570, loss: 0.00404407922179\n",
      "epoch4, iter580, loss: 0.00360790360719\n",
      "epoch4, iter590, loss: 0.00815593916923\n",
      "epoch4, iter600, loss: 0.00274936715141\n",
      "epoch4, iter610, loss: 0.00234906864353\n",
      "epoch4, iter620, loss: 0.00145374715794\n",
      "epoch4, iter630, loss: 0.00184244755656\n",
      "epoch4, iter640, loss: 0.00145368056837\n",
      "epoch4, iter650, loss: 0.00158762454521\n",
      "epoch4, iter660, loss: 0.00245668017305\n",
      "epoch4, iter670, loss: 0.00200239894912\n",
      "epoch4, iter680, loss: 0.00310712354258\n",
      "epoch4, iter690, loss: 0.00192093581427\n",
      "epoch4, iter700, loss: 0.00156489107758\n",
      "epoch4, iter710, loss: 0.00178335222881\n",
      "Finish epoch 3, time elapsed 303.296809912\n",
      "epoch3, pix_acc: 0.973957860471, meanIoU: 0.648782330898, IoUs: [0.6754 0.5431 0.7465 0.7853 0.6335 0.5469 0.6861 0.8003 0.8046 0.7426\n",
      " 0.8740 0.8767 0.8131 0.2345 0.3803 0.5972 0.7098 0.5310 0.6378 0.3570], recall: [0.7260 0.6019 0.7851 0.9018 0.8607 0.5925 0.7231 0.8760 0.8731 0.8132\n",
      " 0.8904 0.9168 0.8553 0.2532 0.3822 0.9057 0.7267 0.9760 0.6896 0.3837], precision: [0.9065 0.8477 0.9381 0.8587 0.7059 0.8765 0.9306 0.9025 0.9112 0.8953\n",
      " 0.9794 0.9525 0.9428 0.7602 0.9870 0.6368 0.9682 0.5380 0.8947 0.8369], fscore: [0.8063 0.7039 0.8548 0.8797 0.7757 0.7071 0.8139 0.8890 0.8917 0.8523\n",
      " 0.9328 0.9343 0.8969 0.3799 0.5510 0.7478 0.8303 0.6936 0.7788 0.5262]\n",
      "epoch5, iter0, loss: 0.0057239192538\n",
      "epoch5, iter10, loss: 0.00248444639146\n",
      "epoch5, iter20, loss: 0.00199863081798\n",
      "epoch5, iter30, loss: 0.00230139913037\n",
      "epoch5, iter40, loss: 0.00274466001429\n",
      "epoch5, iter50, loss: 0.00190391356591\n",
      "epoch5, iter60, loss: 0.00380014069378\n",
      "epoch5, iter70, loss: 0.00210846215487\n",
      "epoch5, iter80, loss: 0.00104717537761\n",
      "epoch5, iter90, loss: 0.00150409969501\n",
      "epoch5, iter100, loss: 0.00159052666277\n",
      "epoch5, iter110, loss: 0.0073993881233\n",
      "epoch5, iter120, loss: 0.00139640131965\n",
      "epoch5, iter130, loss: 0.00459486199543\n",
      "epoch5, iter140, loss: 0.00352917425334\n",
      "epoch5, iter150, loss: 0.00136490131263\n",
      "epoch5, iter160, loss: 0.0020291628316\n",
      "epoch5, iter170, loss: 0.0133833549917\n",
      "epoch5, iter180, loss: 0.00117479788605\n",
      "epoch5, iter190, loss: 0.00428009266034\n",
      "epoch5, iter200, loss: 0.00105898932088\n",
      "epoch5, iter210, loss: 0.00216595921665\n",
      "epoch5, iter220, loss: 0.0011486018775\n",
      "epoch5, iter230, loss: 0.00160752574448\n",
      "epoch5, iter240, loss: 0.00153866910841\n",
      "epoch5, iter250, loss: 0.00208610063419\n",
      "epoch5, iter260, loss: 0.00364981498569\n",
      "epoch5, iter270, loss: 0.00118740077596\n",
      "epoch5, iter280, loss: 0.00276012835093\n",
      "epoch5, iter290, loss: 0.00150548934471\n",
      "epoch5, iter300, loss: 0.00246016704477\n",
      "epoch5, iter310, loss: 0.0213928241283\n",
      "epoch5, iter320, loss: 0.00125611119438\n",
      "epoch5, iter330, loss: 0.00153957493603\n",
      "epoch5, iter340, loss: 0.00147203588858\n",
      "epoch5, iter350, loss: 0.00107571273111\n",
      "epoch5, iter360, loss: 0.0202175602317\n",
      "epoch5, iter370, loss: 0.00925509352237\n",
      "epoch5, iter380, loss: 0.00208395998925\n",
      "epoch5, iter390, loss: 0.00580314267427\n",
      "epoch5, iter400, loss: 0.00111843494233\n",
      "epoch5, iter410, loss: 0.00903459917754\n",
      "epoch5, iter420, loss: 0.00116795918439\n",
      "epoch5, iter430, loss: 0.00129908858798\n",
      "epoch5, iter440, loss: 0.00234624068253\n",
      "epoch5, iter450, loss: 0.00241150055081\n",
      "epoch5, iter460, loss: 0.013019034639\n",
      "epoch5, iter470, loss: 0.00591420475394\n",
      "epoch5, iter480, loss: 0.00278812157921\n",
      "epoch5, iter490, loss: 0.00287117110565\n",
      "epoch5, iter500, loss: 0.00257033691742\n",
      "epoch5, iter510, loss: 0.00380617240444\n",
      "epoch5, iter520, loss: 0.00183018425014\n",
      "epoch5, iter530, loss: 0.00957376230508\n",
      "epoch5, iter540, loss: 0.0013210993493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5, iter550, loss: 0.00143805635162\n",
      "epoch5, iter560, loss: 0.00109380017966\n",
      "epoch5, iter570, loss: 0.00129403744359\n",
      "epoch5, iter580, loss: 0.00961878523231\n",
      "epoch5, iter590, loss: 0.00216142693534\n",
      "epoch5, iter600, loss: 0.00123000063468\n",
      "epoch5, iter610, loss: 0.00287943240255\n",
      "epoch5, iter620, loss: 0.00261048926041\n",
      "epoch5, iter630, loss: 0.00217761006206\n",
      "epoch5, iter640, loss: 0.0052899774164\n",
      "epoch5, iter650, loss: 0.00375493708998\n",
      "epoch5, iter660, loss: 0.0047025885433\n",
      "epoch5, iter670, loss: 0.00849984306842\n",
      "epoch5, iter680, loss: 0.00245377002284\n",
      "epoch5, iter690, loss: 0.005316471681\n",
      "epoch5, iter700, loss: 0.0148469619453\n",
      "epoch5, iter710, loss: 0.00148021418136\n",
      "Finish epoch 4, time elapsed 302.955822945\n",
      "epoch4, pix_acc: 0.981219989264, meanIoU: 0.757867686663, IoUs: [0.7138 0.5434 0.7173 0.8749 0.6710 0.4522 0.7558 0.8032 0.8781 0.7880\n",
      " 0.8573 0.8865 0.8152 0.8980 0.8231 0.9044 0.7833 0.5993 0.6027 0.7898], recall: [0.7419 0.5679 0.7478 0.9061 0.7196 0.4558 0.7990 0.8925 0.9477 0.8334\n",
      " 0.9425 0.9159 0.8616 0.9145 0.9656 0.9271 0.8080 0.8502 0.9355 0.9244], precision: [0.9496 0.9264 0.9463 0.9621 0.9087 0.9828 0.9332 0.8893 0.9228 0.9354\n",
      " 0.9046 0.9651 0.9380 0.9802 0.8480 0.9737 0.9624 0.6701 0.6288 0.8443], fscore: [0.8330 0.7041 0.8354 0.9333 0.8031 0.6228 0.8609 0.8909 0.9351 0.8815\n",
      " 0.9232 0.9399 0.8982 0.9463 0.9030 0.9498 0.8785 0.7494 0.7521 0.8825]\n",
      "epoch6, iter0, loss: 0.00231659831479\n",
      "epoch6, iter10, loss: 0.00196916563436\n",
      "epoch6, iter20, loss: 0.00231522577815\n",
      "epoch6, iter30, loss: 0.00131933111697\n",
      "epoch6, iter40, loss: 0.00572819402441\n",
      "epoch6, iter50, loss: 0.00454160710797\n",
      "epoch6, iter60, loss: 0.00308498600498\n",
      "epoch6, iter70, loss: 0.00188753847033\n",
      "epoch6, iter80, loss: 0.00146015314385\n",
      "epoch6, iter90, loss: 0.001856115181\n",
      "epoch6, iter100, loss: 0.00374387623742\n",
      "epoch6, iter110, loss: 0.00108614785131\n",
      "epoch6, iter120, loss: 0.000810658559203\n",
      "epoch6, iter130, loss: 0.00161357945763\n",
      "epoch6, iter140, loss: 0.00234013516456\n",
      "epoch6, iter150, loss: 0.0128681138158\n",
      "epoch6, iter160, loss: 0.00555648794398\n",
      "epoch6, iter170, loss: 0.00187924085185\n",
      "epoch6, iter180, loss: 0.00462683336809\n",
      "epoch6, iter190, loss: 0.00506822392344\n",
      "epoch6, iter200, loss: 0.00196536467411\n",
      "epoch6, iter210, loss: 0.0151634067297\n",
      "epoch6, iter220, loss: 0.00169773271773\n",
      "epoch6, iter230, loss: 0.00094638671726\n",
      "epoch6, iter240, loss: 0.00144975446165\n",
      "epoch6, iter250, loss: 0.00241967802867\n",
      "epoch6, iter260, loss: 0.00745241157711\n",
      "epoch6, iter270, loss: 0.00184489623643\n",
      "epoch6, iter280, loss: 0.00156397756655\n",
      "epoch6, iter290, loss: 0.00182212644722\n",
      "epoch6, iter300, loss: 0.00193534418941\n",
      "epoch6, iter310, loss: 0.00181669241283\n",
      "epoch6, iter320, loss: 0.00244805123657\n",
      "epoch6, iter330, loss: 0.00204601068981\n",
      "epoch6, iter340, loss: 0.00111483724322\n",
      "epoch6, iter350, loss: 0.00208351830952\n",
      "epoch6, iter360, loss: 0.00131079787388\n",
      "epoch6, iter370, loss: 0.00909502897412\n",
      "epoch6, iter380, loss: 0.000792065402493\n",
      "epoch6, iter390, loss: 0.00192890944891\n",
      "epoch6, iter400, loss: 0.00246409350075\n",
      "epoch6, iter410, loss: 0.00206432281993\n",
      "epoch6, iter420, loss: 0.0331562459469\n",
      "epoch6, iter430, loss: 0.00123078981414\n",
      "epoch6, iter440, loss: 0.0131892971694\n",
      "epoch6, iter450, loss: 0.00159978494048\n",
      "epoch6, iter460, loss: 0.00461914762855\n",
      "epoch6, iter470, loss: 0.00178423256148\n",
      "epoch6, iter480, loss: 0.00180358602665\n",
      "epoch6, iter490, loss: 0.00450654886663\n",
      "epoch6, iter500, loss: 0.00124414812308\n",
      "epoch6, iter510, loss: 0.00297191902064\n",
      "epoch6, iter520, loss: 0.00151021918282\n",
      "epoch6, iter530, loss: 0.00130267126951\n",
      "epoch6, iter540, loss: 0.00197839341126\n",
      "epoch6, iter550, loss: 0.00173676048871\n",
      "epoch6, iter560, loss: 0.00207578204572\n",
      "epoch6, iter570, loss: 0.00207832409069\n",
      "epoch6, iter580, loss: 0.00207154010423\n",
      "epoch6, iter590, loss: 0.00121730181854\n",
      "epoch6, iter600, loss: 0.0410963557661\n",
      "epoch6, iter610, loss: 0.00789143517613\n",
      "epoch6, iter620, loss: 0.00641439761966\n",
      "epoch6, iter630, loss: 0.00466872798279\n",
      "epoch6, iter640, loss: 0.00514023052529\n",
      "epoch6, iter650, loss: 0.00262833898887\n",
      "epoch6, iter660, loss: 0.00207560462877\n",
      "epoch6, iter670, loss: 0.0143637731671\n",
      "epoch6, iter680, loss: 0.00262536667287\n",
      "epoch6, iter690, loss: 0.0076875356026\n",
      "epoch6, iter700, loss: 0.00168032944202\n",
      "epoch6, iter710, loss: 0.00117708335165\n",
      "Finish epoch 5, time elapsed 301.474730015\n",
      "epoch5, pix_acc: 0.982043264574, meanIoU: 0.755454459543, IoUs: [0.6979 0.6150 0.7682 0.8456 0.5762 0.4246 0.7246 0.8079 0.9111 0.7758\n",
      " 0.8374 0.8751 0.6591 0.9093 0.7115 0.9055 0.7637 0.7861 0.6379 0.8764], recall: [0.7266 0.6530 0.8245 0.9396 0.8786 0.4463 0.7732 0.8629 0.9657 0.9181\n",
      " 0.9279 0.9619 0.9424 0.9388 0.7148 0.9384 0.7959 0.9615 0.9498 0.9504], precision: [0.9464 0.9137 0.9183 0.8943 0.6260 0.8974 0.9203 0.9269 0.9416 0.8334\n",
      " 0.8957 0.9065 0.6868 0.9666 0.9936 0.9628 0.9498 0.8116 0.6602 0.9185], fscore: [0.8221 0.7616 0.8689 0.9164 0.7311 0.5961 0.8403 0.8937 0.9535 0.8737\n",
      " 0.9115 0.9334 0.7946 0.9525 0.8314 0.9504 0.8660 0.8802 0.7789 0.9341]\n",
      "epoch7, iter0, loss: 0.00138668238651\n",
      "epoch7, iter10, loss: 0.00164565735031\n",
      "epoch7, iter20, loss: 0.00161554582883\n",
      "epoch7, iter30, loss: 0.00248265918344\n",
      "epoch7, iter40, loss: 0.00108415645082\n",
      "epoch7, iter50, loss: 0.00275259464979\n",
      "epoch7, iter60, loss: 0.00222923164256\n",
      "epoch7, iter70, loss: 0.00136953615583\n",
      "epoch7, iter80, loss: 0.00171442120336\n",
      "epoch7, iter90, loss: 0.00344251585193\n",
      "epoch7, iter100, loss: 0.00516440859064\n",
      "epoch7, iter110, loss: 0.00153991405386\n",
      "epoch7, iter120, loss: 0.00360601441935\n",
      "epoch7, iter130, loss: 0.00453792139888\n",
      "epoch7, iter140, loss: 0.00117813132238\n",
      "epoch7, iter150, loss: 0.00109781476203\n",
      "epoch7, iter160, loss: 0.000875606492627\n",
      "epoch7, iter170, loss: 0.00186209625099\n",
      "epoch7, iter180, loss: 0.000979524338618\n",
      "epoch7, iter190, loss: 0.0019226212753\n",
      "epoch7, iter200, loss: 0.00663011940196\n",
      "epoch7, iter210, loss: 0.00648038974032\n",
      "epoch7, iter220, loss: 0.00863616820425\n",
      "epoch7, iter230, loss: 0.00293150078505\n",
      "epoch7, iter240, loss: 0.00390873011202\n",
      "epoch7, iter250, loss: 0.00147786794696\n",
      "epoch7, iter260, loss: 0.000992299872451\n",
      "epoch7, iter270, loss: 0.00162383902352\n",
      "epoch7, iter280, loss: 0.00212627509609\n",
      "epoch7, iter290, loss: 0.00160164746922\n",
      "epoch7, iter300, loss: 0.00101475347765\n",
      "epoch7, iter310, loss: 0.00466716941446\n",
      "epoch7, iter320, loss: 0.0020437836647\n",
      "epoch7, iter330, loss: 0.00190649589058\n",
      "epoch7, iter340, loss: 0.000812415149994\n",
      "epoch7, iter350, loss: 0.00149590987712\n",
      "epoch7, iter360, loss: 0.00313034444116\n",
      "epoch7, iter370, loss: 0.00190714758355\n",
      "epoch7, iter380, loss: 0.00168882124126\n",
      "epoch7, iter390, loss: 0.00154425762594\n",
      "epoch7, iter400, loss: 0.00137778138742\n",
      "epoch7, iter410, loss: 0.00203828886151\n",
      "epoch7, iter420, loss: 0.001733229612\n",
      "epoch7, iter430, loss: 0.00219098152593\n",
      "epoch7, iter440, loss: 0.00156293041073\n",
      "epoch7, iter450, loss: 0.00855606421828\n",
      "epoch7, iter460, loss: 0.00241654575802\n",
      "epoch7, iter470, loss: 0.00151877559256\n",
      "epoch7, iter480, loss: 0.011946843937\n",
      "epoch7, iter490, loss: 0.00228260504082\n",
      "epoch7, iter500, loss: 0.00137492374051\n",
      "epoch7, iter510, loss: 0.00120590685401\n",
      "epoch7, iter520, loss: 0.00070093863178\n",
      "epoch7, iter530, loss: 0.00431693950668\n",
      "epoch7, iter540, loss: 0.00217527104542\n",
      "epoch7, iter550, loss: 0.00182848365512\n",
      "epoch7, iter560, loss: 0.00205842358992\n",
      "epoch7, iter570, loss: 0.00176454067696\n",
      "epoch7, iter580, loss: 0.00599938258529\n",
      "epoch7, iter590, loss: 0.00109387806151\n",
      "epoch7, iter600, loss: 0.00216412660666\n",
      "epoch7, iter610, loss: 0.00176949554589\n",
      "epoch7, iter620, loss: 0.00227159052156\n",
      "epoch7, iter630, loss: 0.00275299604982\n",
      "epoch7, iter640, loss: 0.00471725827083\n",
      "epoch7, iter650, loss: 0.00114241661504\n",
      "epoch7, iter660, loss: 0.00311311916448\n",
      "epoch7, iter670, loss: 0.0132024753839\n",
      "epoch7, iter680, loss: 0.0012512600515\n",
      "epoch7, iter690, loss: 0.0015011188807\n",
      "epoch7, iter700, loss: 0.00275079393759\n",
      "epoch7, iter710, loss: 0.00161614152603\n",
      "Finish epoch 6, time elapsed 303.346663952\n",
      "epoch6, pix_acc: 0.978764176718, meanIoU: 0.720261933052, IoUs: [0.7138 0.6135 0.7709 0.8881 0.6800 0.6840 0.7665 0.7351 0.7929 0.7431\n",
      " 0.8458 0.8941 0.8450 0.9129 0.3986 0.6570 0.7290 0.5068 0.7056 0.5225], recall: [0.7883 0.6766 0.8424 0.9349 0.8541 0.7966 0.8209 0.7824 0.8296 0.8520\n",
      " 0.8778 0.9659 0.9259 0.9544 0.4093 0.9371 0.7703 0.5293 0.9522 0.9754], precision: [0.8831 0.8680 0.9008 0.9466 0.7693 0.8287 0.9205 0.9239 0.9471 0.8533\n",
      " 0.9587 0.9233 0.9063 0.9546 0.9380 0.6873 0.9314 0.9226 0.7316 0.5294], fscore: [0.8330 0.7605 0.8706 0.9407 0.8095 0.8124 0.8678 0.8473 0.8845 0.8526\n",
      " 0.9165 0.9441 0.9160 0.9545 0.5700 0.7930 0.8433 0.6727 0.8274 0.6863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch8, iter0, loss: 0.00242837960832\n",
      "epoch8, iter10, loss: 0.0032815868035\n",
      "epoch8, iter20, loss: 0.00112714443821\n",
      "epoch8, iter30, loss: 0.0108493231237\n",
      "epoch8, iter40, loss: 0.00318028940819\n",
      "epoch8, iter50, loss: 0.00199103122577\n",
      "epoch8, iter60, loss: 0.00179940776434\n",
      "epoch8, iter70, loss: 0.000787889759522\n",
      "epoch8, iter80, loss: 0.00341220851988\n",
      "epoch8, iter90, loss: 0.00150317326188\n",
      "epoch8, iter100, loss: 0.00172285153531\n",
      "epoch8, iter110, loss: 0.0011941739358\n",
      "epoch8, iter120, loss: 0.00302766659297\n",
      "epoch8, iter130, loss: 0.0016195679782\n",
      "epoch8, iter140, loss: 0.000633783231024\n",
      "epoch8, iter150, loss: 0.00420410325751\n",
      "epoch8, iter160, loss: 0.00140748044942\n",
      "epoch8, iter170, loss: 0.00191096647177\n",
      "epoch8, iter180, loss: 0.00231662276201\n",
      "epoch8, iter190, loss: 0.00202096044086\n",
      "epoch8, iter200, loss: 0.00204516993836\n",
      "epoch8, iter210, loss: 0.00114472932182\n",
      "epoch8, iter220, loss: 0.00132633047178\n",
      "epoch8, iter230, loss: 0.00782913621515\n",
      "epoch8, iter240, loss: 0.00343288597651\n",
      "epoch8, iter250, loss: 0.00284656276926\n",
      "epoch8, iter260, loss: 0.00112354324665\n",
      "epoch8, iter270, loss: 0.00237586442381\n",
      "epoch8, iter280, loss: 0.000985328224488\n",
      "epoch8, iter290, loss: 0.00700799468905\n",
      "epoch8, iter300, loss: 0.00155427167192\n",
      "epoch8, iter310, loss: 0.00201010634191\n",
      "epoch8, iter320, loss: 0.00274181063287\n",
      "epoch8, iter330, loss: 0.00157507695258\n",
      "epoch8, iter340, loss: 0.00189942121506\n",
      "epoch8, iter350, loss: 0.000834375852719\n",
      "epoch8, iter360, loss: 0.00205959938467\n",
      "epoch8, iter370, loss: 0.00244026607834\n",
      "epoch8, iter380, loss: 0.00119551760145\n",
      "epoch8, iter390, loss: 0.0089494343847\n",
      "epoch8, iter400, loss: 0.00295797246508\n",
      "epoch8, iter410, loss: 0.001843311009\n",
      "epoch8, iter420, loss: 0.0020757119637\n",
      "epoch8, iter430, loss: 0.00238017109223\n",
      "epoch8, iter440, loss: 0.00338238757104\n",
      "epoch8, iter450, loss: 0.00123549578711\n",
      "epoch8, iter460, loss: 0.00174409861211\n",
      "epoch8, iter470, loss: 0.000528187025338\n",
      "epoch8, iter480, loss: 0.00187092635315\n",
      "epoch8, iter490, loss: 0.00244071823545\n",
      "epoch8, iter500, loss: 0.0023985535372\n",
      "epoch8, iter510, loss: 0.00224517518654\n",
      "epoch8, iter520, loss: 0.00140800920781\n",
      "epoch8, iter530, loss: 0.00305333919823\n",
      "epoch8, iter540, loss: 0.00168388732709\n",
      "epoch8, iter550, loss: 0.00152370694559\n",
      "epoch8, iter560, loss: 0.00156873348169\n",
      "epoch8, iter570, loss: 0.00109326350503\n",
      "epoch8, iter580, loss: 0.00118578714319\n",
      "epoch8, iter590, loss: 0.00134427833837\n",
      "epoch8, iter600, loss: 0.00119936862029\n",
      "epoch8, iter610, loss: 0.00479960301891\n",
      "epoch8, iter620, loss: 0.000948748609517\n",
      "epoch8, iter630, loss: 0.00525080924854\n",
      "epoch8, iter640, loss: 0.000597293314058\n",
      "epoch8, iter650, loss: 0.00249891239218\n",
      "epoch8, iter660, loss: 0.00181649380829\n",
      "epoch8, iter670, loss: 0.00371997873299\n",
      "epoch8, iter680, loss: 0.00142596662045\n",
      "epoch8, iter690, loss: 0.0123165538535\n",
      "epoch8, iter700, loss: 0.00126264221035\n",
      "epoch8, iter710, loss: 0.00158911012113\n",
      "Finish epoch 7, time elapsed 303.227796078\n",
      "epoch7, pix_acc: 0.984713073374, meanIoU: 0.800046443154, IoUs: [0.7175 0.5635 0.8057 0.8527 0.6716 0.5494 0.7615 0.8127 0.9290 0.7876\n",
      " 0.9009 0.9221 0.8415 0.8109 0.7404 0.9189 0.8297 0.8601 0.8134 0.9118], recall: [0.8031 0.6850 0.8471 0.9446 0.9268 0.5514 0.8488 0.9338 0.9581 0.8273\n",
      " 0.9215 0.9726 0.8829 0.8223 0.9657 0.9571 0.8694 0.9278 0.9423 0.9517], precision: [0.8707 0.7607 0.9429 0.8976 0.7093 0.9935 0.8810 0.8624 0.9683 0.9426\n",
      " 0.9757 0.9466 0.9472 0.9833 0.7604 0.9584 0.9479 0.9217 0.8561 0.9560], fscore: [0.8355 0.7208 0.8924 0.9205 0.8036 0.7092 0.8646 0.8967 0.9632 0.8812\n",
      " 0.9479 0.9594 0.9139 0.8956 0.8509 0.9577 0.9069 0.9248 0.8971 0.9539]\n",
      "epoch9, iter0, loss: 0.00206683832221\n",
      "epoch9, iter10, loss: 0.00107855850365\n",
      "epoch9, iter20, loss: 0.00525031192228\n",
      "epoch9, iter30, loss: 0.00299344980158\n",
      "epoch9, iter40, loss: 0.00140409322921\n",
      "epoch9, iter50, loss: 0.00188889540732\n",
      "epoch9, iter60, loss: 0.00159451528452\n",
      "epoch9, iter70, loss: 0.00309255858883\n",
      "epoch9, iter80, loss: 0.00122314097825\n",
      "epoch9, iter90, loss: 0.0121607324108\n",
      "epoch9, iter100, loss: 0.00785544328392\n",
      "epoch9, iter110, loss: 0.00146155129187\n",
      "epoch9, iter120, loss: 0.00381447421387\n",
      "epoch9, iter130, loss: 0.00441608065739\n",
      "epoch9, iter140, loss: 0.00206089345738\n",
      "epoch9, iter150, loss: 0.00126645551063\n",
      "epoch9, iter160, loss: 0.00644670147449\n",
      "epoch9, iter170, loss: 0.00174597429577\n",
      "epoch9, iter180, loss: 0.00114687846508\n",
      "epoch9, iter190, loss: 0.00302187958732\n",
      "epoch9, iter200, loss: 0.00292092864402\n",
      "epoch9, iter210, loss: 0.00205017719418\n",
      "epoch9, iter220, loss: 0.00137078820262\n",
      "epoch9, iter230, loss: 0.00331195397303\n",
      "epoch9, iter240, loss: 0.00170410389546\n",
      "epoch9, iter250, loss: 0.0129144471139\n",
      "epoch9, iter260, loss: 0.00228080502711\n",
      "epoch9, iter270, loss: 0.00133369362447\n",
      "epoch9, iter280, loss: 0.00186772563029\n",
      "epoch9, iter290, loss: 0.00446062721312\n",
      "epoch9, iter300, loss: 0.00297338794917\n",
      "epoch9, iter310, loss: 0.00290432572365\n",
      "epoch9, iter320, loss: 0.00109088805038\n",
      "epoch9, iter330, loss: 0.00197915453464\n",
      "epoch9, iter340, loss: 0.00122121861205\n",
      "epoch9, iter350, loss: 0.00168368406594\n",
      "epoch9, iter360, loss: 0.00982420518994\n",
      "epoch9, iter370, loss: 0.00443058554083\n",
      "epoch9, iter380, loss: 0.00190388283227\n",
      "epoch9, iter390, loss: 0.00296221650206\n",
      "epoch9, iter400, loss: 0.00216278573498\n",
      "epoch9, iter410, loss: 0.0048761353828\n",
      "epoch9, iter420, loss: 0.00280895107426\n",
      "epoch9, iter430, loss: 0.00218132697046\n",
      "epoch9, iter440, loss: 0.00144086463843\n",
      "epoch9, iter450, loss: 0.00138503755443\n",
      "epoch9, iter460, loss: 0.00208159629256\n",
      "epoch9, iter470, loss: 0.000543130736332\n",
      "epoch9, iter480, loss: 0.00147521134932\n",
      "epoch9, iter490, loss: 0.00207832478918\n",
      "epoch9, iter500, loss: 0.0149431861937\n",
      "epoch9, iter510, loss: 0.00176089955494\n",
      "epoch9, iter520, loss: 0.00179237127304\n",
      "epoch9, iter530, loss: 0.00108666275628\n",
      "epoch9, iter540, loss: 0.00122223165818\n",
      "epoch9, iter550, loss: 0.0011629028013\n",
      "epoch9, iter560, loss: 0.0025551118888\n",
      "epoch9, iter570, loss: 0.00169798161369\n",
      "epoch9, iter580, loss: 0.00164021505043\n",
      "epoch9, iter590, loss: 0.00250368472189\n",
      "epoch9, iter600, loss: 0.00448330212384\n",
      "epoch9, iter610, loss: 0.00155024451669\n",
      "epoch9, iter620, loss: 0.00157930760179\n",
      "epoch9, iter630, loss: 0.00207621278241\n",
      "epoch9, iter640, loss: 0.00212824437767\n",
      "epoch9, iter650, loss: 0.00457384437323\n",
      "epoch9, iter660, loss: 0.00616651587188\n",
      "epoch9, iter670, loss: 0.00152595061809\n",
      "epoch9, iter680, loss: 0.0016212600749\n",
      "epoch9, iter690, loss: 0.00235631898977\n",
      "epoch9, iter700, loss: 0.00186601665337\n",
      "epoch9, iter710, loss: 0.00214248243719\n",
      "Finish epoch 8, time elapsed 302.637755156\n",
      "epoch8, pix_acc: 0.964825911458, meanIoU: 0.482550637084, IoUs: [0.4327 0.1857 0.6870 0.2444 0.4638 0.7848 0.0017 0.5138 0.8939 0.5594\n",
      " 0.4405 0.6034 0.3032 0.7426 0.9111 0.8117 0.2960 0.0165 0.2442 0.5147], recall: [0.7913 0.1878 0.7728 0.2469 0.4662 0.8786 0.0017 0.9067 0.9714 0.6985\n",
      " 0.4499 0.6806 0.9527 0.7669 0.9536 0.8280 0.3000 0.0166 0.2520 0.9662], precision: [0.4884 0.9436 0.8608 0.9589 0.9887 0.8803 0.7065 0.5424 0.9181 0.7375\n",
      " 0.9547 0.8419 0.3079 0.9591 0.9535 0.9763 0.9569 0.7609 0.8870 0.5242], fscore: [0.6040 0.3132 0.8144 0.3927 0.6337 0.8794 0.0035 0.6788 0.9440 0.7175\n",
      " 0.6116 0.7527 0.4653 0.8523 0.9535 0.8961 0.4568 0.0324 0.3925 0.6796]\n",
      "epoch10, iter0, loss: 0.00942623708397\n",
      "epoch10, iter10, loss: 0.00259572640061\n",
      "epoch10, iter20, loss: 0.00185016356409\n",
      "epoch10, iter30, loss: 0.00197372329421\n",
      "epoch10, iter40, loss: 0.00351047236472\n",
      "epoch10, iter50, loss: 0.00142051535659\n",
      "epoch10, iter60, loss: 0.00141363847069\n",
      "epoch10, iter70, loss: 0.000727751350496\n",
      "epoch10, iter80, loss: 0.00143942038994\n",
      "epoch10, iter90, loss: 0.00254268827848\n",
      "epoch10, iter100, loss: 0.00136400747579\n",
      "epoch10, iter110, loss: 0.00316555099562\n",
      "epoch10, iter120, loss: 0.00219113472849\n",
      "epoch10, iter130, loss: 0.00244033406489\n",
      "epoch10, iter140, loss: 0.00116260827053\n",
      "epoch10, iter150, loss: 0.00146698579192\n",
      "epoch10, iter160, loss: 0.00133722939063\n",
      "epoch10, iter170, loss: 0.00168499362189\n",
      "epoch10, iter180, loss: 0.00145339779556\n",
      "epoch10, iter190, loss: 0.00134339462966\n",
      "epoch10, iter200, loss: 0.00345277925953\n",
      "epoch10, iter210, loss: 0.000635483884253\n",
      "epoch10, iter220, loss: 0.00160973530728\n",
      "epoch10, iter230, loss: 0.00246129161678\n",
      "epoch10, iter240, loss: 0.00592294475064\n",
      "epoch10, iter250, loss: 0.00149003474507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch10, iter260, loss: 0.000816636427771\n",
      "epoch10, iter270, loss: 0.0010796696879\n",
      "epoch10, iter280, loss: 0.0016805625055\n",
      "epoch10, iter290, loss: 0.00151995744091\n",
      "epoch10, iter300, loss: 0.00388344796374\n",
      "epoch10, iter310, loss: 0.00130896421615\n",
      "epoch10, iter320, loss: 0.00102826114744\n",
      "epoch10, iter330, loss: 0.00374910491519\n",
      "epoch10, iter340, loss: 0.00268617738038\n",
      "epoch10, iter350, loss: 0.00246823369525\n",
      "epoch10, iter360, loss: 0.000756674387958\n",
      "epoch10, iter370, loss: 0.00401011668146\n",
      "epoch10, iter380, loss: 0.000840597902425\n",
      "epoch10, iter390, loss: 0.00394473597407\n",
      "epoch10, iter400, loss: 0.00280891079456\n",
      "epoch10, iter410, loss: 0.0132846720517\n",
      "epoch10, iter420, loss: 0.00281669595279\n",
      "epoch10, iter430, loss: 0.00217600516044\n",
      "epoch10, iter440, loss: 0.00735782878473\n",
      "epoch10, iter450, loss: 0.00156094343401\n",
      "epoch10, iter460, loss: 0.00936777424067\n",
      "epoch10, iter470, loss: 0.00110096030403\n",
      "epoch10, iter480, loss: 0.00174385251012\n",
      "epoch10, iter490, loss: 0.00365319848061\n",
      "epoch10, iter500, loss: 0.0042849755846\n",
      "epoch10, iter510, loss: 0.00181782385334\n",
      "epoch10, iter520, loss: 0.00186527147889\n",
      "epoch10, iter530, loss: 0.00179666804615\n",
      "epoch10, iter540, loss: 0.00250026024878\n",
      "epoch10, iter550, loss: 0.00254984083585\n",
      "epoch10, iter560, loss: 0.00144026475027\n",
      "epoch10, iter570, loss: 0.00127337512095\n",
      "epoch10, iter580, loss: 0.00189555995166\n",
      "epoch10, iter590, loss: 0.00183371850289\n",
      "epoch10, iter600, loss: 0.00167318619788\n",
      "epoch10, iter610, loss: 0.00197820411995\n",
      "epoch10, iter620, loss: 0.00213649915531\n",
      "epoch10, iter630, loss: 0.00201418460347\n",
      "epoch10, iter640, loss: 0.000866870977916\n",
      "epoch10, iter650, loss: 0.00121489947196\n",
      "epoch10, iter660, loss: 0.00147531018592\n",
      "epoch10, iter670, loss: 0.00463443016633\n",
      "epoch10, iter680, loss: 0.0012983600609\n",
      "epoch10, iter690, loss: 0.00511231040582\n",
      "epoch10, iter700, loss: 0.0106453411281\n",
      "epoch10, iter710, loss: 0.00497835269198\n",
      "Finish epoch 9, time elapsed 302.426301956\n",
      "epoch9, pix_acc: 0.980627814327, meanIoU: 0.712142069936, IoUs: [0.6199 0.4754 0.5946 0.8039 0.8328 0.8635 0.7118 0.6273 0.8668 0.6849\n",
      " 0.5949 0.6073 0.8274 0.8081 0.9042 0.8898 0.6696 0.5039 0.8195 0.5373], recall: [0.8222 0.4922 0.6103 0.8996 0.9004 0.8992 0.8028 0.9307 0.8895 0.7908\n",
      " 0.9166 0.6189 0.9058 0.8583 0.9845 0.9334 0.6864 0.5364 0.8845 0.9348], precision: [0.7159 0.9332 0.9585 0.8832 0.9173 0.9561 0.8627 0.6580 0.9714 0.8364\n",
      " 0.6289 0.9699 0.9053 0.9324 0.9172 0.9502 0.9647 0.8929 0.9176 0.5583], fscore: [0.7653 0.6445 0.7458 0.8913 0.9088 0.9268 0.8317 0.7709 0.9287 0.8130\n",
      " 0.7460 0.7557 0.9055 0.8938 0.9497 0.9417 0.8021 0.6702 0.9008 0.6991]\n"
     ]
    }
   ],
   "source": [
    "fcn_model.load_state_dict(torch.load(\"/home/arg/pytorch_fcn/models/ds/style.pkl\"))\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prediction(\"FCNs_ds_epoch9_epoch9.pkl\")\n",
    "# prediction(\"FCNs_ds_epoch9_epoch9.pkl\")\n",
    "# prediction(\"FCNs_ds_epoch9_epoch9.pkl\")\n",
    "\n",
    "\n",
    "# # print(\"real_batch4_epoch9\")\n",
    "# # # prediction(\"real_batch4_epoch9.pkl\")\n",
    "# # print(\"virtual_batch4_epoch3\")\n",
    "# # prediction(\"virtual_batch4_epoch3.pkl\")\n",
    "# # print(\"style_transfer_batch4_epoch8\")\n",
    "# # prediction(\"style_transfer_batch4_epoch8.pkl\")\n",
    "\n",
    "# print(\"real_806\")\n",
    "# prediction(\"real_806.pkl\")\n",
    "# print(\"virtual with 806 real image fine-tune\")\n",
    "# prediction(\"virtual_real_806.pkl\")\n",
    "# print(\"style with 806 real image fine-tune\")\n",
    "# prediction(\"style_real_806.pkl\")\n",
    "# print(\"=================================================================\")\n",
    "# print(\"real_403\")\n",
    "# prediction(\"real_403.pkl\")\n",
    "# print(\"virtual with 403 real image fine-tune\")\n",
    "# prediction(\"virtual_real_403.pkl\")\n",
    "# print(\"style with 403 real image fine-tune\")\n",
    "# prediction(\"style_real_403.pkl\")\n",
    "# print(\"=================================================================\")\n",
    "# print(\"real_268\")\n",
    "# prediction(\"real_268.pkl\")\n",
    "# print(\"virtual with 268 real image fine-tune\")\n",
    "# prediction(\"virtual_real_268.pkl\")\n",
    "# print(\"style with 268 real image fine-tune\")\n",
    "# prediction(\"style_real_268.pkl\")\n",
    "# # print(\"style with 268 real image fine-tune\")\n",
    "# # prediction(\"style_real_268_f.pkl\")\n",
    "\n",
    "# print(\"=================================================================\")\n",
    "# print(\"real_201\")\n",
    "# prediction(\"real_201.pkl\")\n",
    "# print(\"virtual with 201 real image fine-tune\")\n",
    "# prediction(\"virtual_real_201.pkl\")\n",
    "# # print(\"virtual with 201 real image fine-tune\")\n",
    "# # prediction(\"virtual_real_201_f.pkl\")\n",
    "# print(\"style with 201 real image fine-tune\")\n",
    "# prediction(\"style_real_201.pkl\")\n",
    "# # print(\"style with 201 real image fine-tune\")\n",
    "# # prediction(\"style_real_201_f.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_prediction(model_name, score_dir_name):\n",
    "    state_dict = torch.load(os.path.join(model_dir, model_name))\n",
    "    fcn_model.load_state_dict(state_dict)\n",
    "    \n",
    "    fcn_model.eval()\n",
    "    TP = np.zeros(n_class-1)\n",
    "    FN = np.zeros(n_class-1)\n",
    "    FP = np.zeros(n_class-1)\n",
    "    total_ious = []\n",
    "    pixel_accs = []\n",
    "    for iter, batch in enumerate(val_loader):\n",
    "        if use_gpu:\n",
    "            inputs = Variable(batch['X'].cuda())\n",
    "        else:\n",
    "            inputs = Variable(batch['X'])\n",
    "\n",
    "        output = fcn_model(inputs)\n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        N, _, h, w = output.shape\n",
    "        pred = output.transpose(0, 2, 3, 1).reshape(-1, n_class).argmax(axis=1).reshape(N, h, w)\n",
    "\n",
    "        target = batch['l'].cpu().numpy().reshape(N, h, w)\n",
    "        \n",
    "        for p, t in zip(pred, target):\n",
    "            pixel_accs.append(pixel_acc(p, t))\n",
    "            _TP, _FN, _FP =  analysis(p, t, h, w)\n",
    "            TP += _TP[1:n_class]\n",
    "            FN += _FN[1:n_class]\n",
    "            FP += _FP[1:n_class]\n",
    "\n",
    "    recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    ious = TP / (TP + FN + FP)\n",
    "    fscore = 2*TP / (2*TP + FN + FP)\n",
    "    total_ious = np.array(total_ious).T  # n_class * val_len\n",
    "    pixel_accs = np.array(pixel_accs).mean()\n",
    "    \n",
    "    np.set_printoptions(formatter=dict(float=lambda t:\"%6.4f\" % t))\n",
    "    print(\"model: {}\\npix_acc: {}\\nmeanIoU: {}\\nIoUs:      {}\\nrecall:    {}\\nprecision: {}\\nfscore:    {}\".format(model_name,pixel_accs, np.nanmean(ious),ious, recall, precision, fscore))\n",
    "    print ('             3m     andes   coca  crayo  folger kellog  milo   stax  swiss  viva')\n",
    "    score_dir_name = score_dir + '/' + score_dir_name\n",
    "    if not os.path.exists(score_dir_name):\n",
    "        os.makedirs(score_dir_name)\n",
    "    \n",
    "    f1 = open(score_dir_name + \"/cls_acc_log.txt\",\"a+\")\n",
    "    f1.write('model: {}, pix_acc: {} \\n'.format(model_name, pixel_accs))\n",
    "    f2 = open(score_dir_name + \"/cls_iou_log.txt\",\"a+\")\n",
    "    f2.write('model: {}, class ious: {} \\n'.format(model_name, ious))\n",
    "    f3 = open(score_dir_name + \"/mean_iou_log.txt\",\"a+\")\n",
    "    f3.write('model: {}, mean IoU: {} \\n'.format(model_name, np.nanmean(ious))) \n",
    "    f4 = open(score_dir_name + \"/recall_log.txt\",\"a+\")\n",
    "    f4.write('model: {}, class recall: {} \\n'.format(model_name, recall))\n",
    "    f5 = open(score_dir_name + \"/precision_log.txt\",\"a+\")\n",
    "    f5.write('model: {}, class precision: {} \\n'.format(model_name, precision))    \n",
    "    f6 = open(score_dir_name + \"/fscore_log.txt\",\"a+\")\n",
    "    f6.write('model: {}, class fscore: {} \\n'.format(model_name, fscore))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(\"real_806\")\n",
    "# val_prediction(\"real_806.pkl\", \"real_806\")\n",
    "# print(\"\\n\\nvirtual with 806 real image fine-tune\")\n",
    "# val_prediction(\"virtual_real_806.pkl\", \"virtual_real_806\")\n",
    "# print(\"\\n\\nstyle with 806 real image fine-tune\")\n",
    "# val_prediction(\"style_real_806.pkl\", \"style_real_806\")\n",
    "\n",
    "# print(\"real_403\")\n",
    "# val_prediction(\"real_403.pkl\", \"real_403\")\n",
    "# print(\"\\n\\nvirtual with 403 real image fine-tune\")\n",
    "# val_prediction(\"virtual_real_403.pkl\", \"virtual_real_403\")\n",
    "# print(\"\\n\\nstyle with 403 real image fine-tune\")\n",
    "# val_prediction(\"style_real_403.pkl\", \"style_real_403\")\n",
    "\n",
    "# print(\"real_268\")\n",
    "# val_prediction(\"real_268.pkl\", \"real_268\")\n",
    "# print(\"\\n\\nvirtual with 268 real image fine-tune\")\n",
    "# val_prediction(\"virtual_real_268.pkl\", \"virtual_real_268\")\n",
    "# print(\"\\n\\nstyle with 268 real image fine-tune\")\n",
    "# val_prediction(\"style_real_268.pkl\", \"style_real_268\")\n",
    "# print(\"\\n\\nfail, style with 268 real image fine-tune\")\n",
    "# val_prediction(\"style_real_268_f.pkl\", \"style_real_268_f\")\n",
    "\n",
    "# print(\"real_201\")\n",
    "# val_prediction(\"real_201.pkl\", \"real_201\")\n",
    "# print(\"\\n\\nvirtual with 201 real image fine-tune\")\n",
    "# val_prediction(\"virtual_real_201.pkl\", \"virtual_real_201\")\n",
    "# print(\"\\n\\nstyle with 201 real image fine-tune\")\n",
    "# val_prediction(\"style_real_201.pkl\", \"style_real_201\")\n",
    "# print(\"\\n\\nfail, virtual with 201 real image fine-tune\")\n",
    "# val_prediction(\"virtual_real_201_f.pkl\", \"virtual_real_201_f\")\n",
    "# print(\"\\n\\nfail, style with 201 real image fine-tune\")\n",
    "# val_prediction(\"style_real_201_f.pkl\", \"style_real_201_f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"real_806\")\n",
    "# prediction(\"real_806.pkl\")\n",
    "# print(\"virtual with 806 real image fine-tune\")\n",
    "# prediction(\"virtual_real_806.pkl\")\n",
    "# print(\"style with 806 real image fine-tune\")\n",
    "# prediction(\"style_real_806.pkl\")\n",
    "# print(\"=================================================================\")\n",
    "# print(\"real_403\")\n",
    "# prediction(\"real_403.pkl\")\n",
    "# print(\"virtual with 403 real image fine-tune\")\n",
    "# prediction(\"virtual_real_403.pkl\")\n",
    "# print(\"style with 403 real image fine-tune\")\n",
    "# prediction(\"style_real_403.pkl\")\n",
    "# print(\"=================================================================\")\n",
    "# print(\"real_268\")\n",
    "# prediction(\"real_268.pkl\")\n",
    "# print(\"virtual with 268 real image fine-tune\")\n",
    "# prediction(\"virtual_real_268.pkl\")\n",
    "# print(\"style with 268 real image fine-tune\")\n",
    "# prediction(\"style_real_268.pkl\")\n",
    "# print(\"style with 268 real image fine-tune\")\n",
    "# prediction(\"style_real_268_f.pkl\")\n",
    "\n",
    "# print(\"=================================================================\")\n",
    "# print(\"real_201\")\n",
    "# prediction(\"real_201.pkl\")\n",
    "# print(\"virtual with 201 real image fine-tune\")\n",
    "# prediction(\"virtual_real_201.pkl\")\n",
    "# print(\"virtual with 201 real image fine-tune\")\n",
    "# prediction(\"virtual_real_201_f.pkl\")\n",
    "# print(\"style with 201 real image fine-tune\")\n",
    "# prediction(\"style_real_201.pkl\")\n",
    "# print(\"style with 201 real image fine-tune\")\n",
    "# prediction(\"style_real_201_f.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
